{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the 20-winter mean BSS and the weather regime sorted BSS\n",
    "Version 22 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "continuous timeseries of daily CRPS values for every model in csv-format (including the climatological ensemble), continuous timeseries of ground truth temperature in csv-format, timeseries of catagorical weather regimes in csv-format\n",
    "### Output: png-files\n",
    "20-winter mean BSS and weather regime sorted BSS plots in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions, the style sheet for plotting and the configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the style file which should be used for plotting.\n",
    "style_file_for_plotting = './Style_File_Matplotlib.mplstyle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configurations/'\n",
    "ifile_configurations = 'Configurations_Plotting_BSS_Multi_Winter_Mean_and_WR_sorted.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the style sheet for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the style sheet to be used by matplotlib for plotting. This will update the plotting\n",
    "# parameters to e.g. have the right font, font size and figure size. The latter is adjusted to\n",
    "# the textwidth of the LaTeX-document in order to avoid re-scaling the plot and changing \n",
    "# thereby the font size again.\n",
    "plt.style.use(style_file_for_plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file (nothing needs to be changed here).\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the ground truth and weather regime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the continuous ground truth and remove any unnamed columns as well as the index \n",
    "# column.\n",
    "df_ground_truth_14d = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth_cold_waves_14d'])\n",
    "df_ground_truth_14d = df_ground_truth_14d.loc[:, ~df_ground_truth_14d.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth_14d = df_ground_truth_14d.drop(['index'], axis =1 )\n",
    "\n",
    "df_ground_truth_21d = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth_cold_waves_21d'])\n",
    "df_ground_truth_21d = df_ground_truth_21d.loc[:, ~df_ground_truth_21d.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth_21d = df_ground_truth_21d.drop(['index'], axis =1 )\n",
    "\n",
    "df_ground_truth_28d = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth_cold_waves_28d'])\n",
    "df_ground_truth_28d = df_ground_truth_28d.loc[:, ~df_ground_truth_28d.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth_28d = df_ground_truth_28d.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth_14d.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth_14d.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Continuous ground truth: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_ground_truth_14d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the continuous weather regime data and remove any unnamed columns as well as the index \n",
    "# column.\n",
    "df_weather_regimes = read_in_csv_data(config['PATH_weather_regimes'], config['ifile_weather_regimes'])\n",
    "df_weather_regimes = df_weather_regimes.rename(columns = {'1' : 'date', '0' : 'time', 'Unnamed: 2' : 'WR'})\n",
    "df_weather_regimes = df_weather_regimes.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the weather regime data.\n",
    "time_column_name_weather_regimes = df_weather_regimes.columns[0]\n",
    "var_column_name_weather_regimes = df_weather_regimes.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Prevailing weather regime: ')\n",
    "print(var_column_name_weather_regimes)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_weather_regimes)\n",
    "print('Dataframe containing the weather regimes: ')\n",
    "df_weather_regimes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the bs values of the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the timeseries of the climatological ensemble's bs and remove any unnamed columns \n",
    "# as well as the index column.\n",
    "df_climatological_ensemble_bs = read_in_csv_data(config['PATH_climatological_ensemble_bs'], config['ifile_climatological_ensemble_bs'])\n",
    "df_climatological_ensemble_bs = df_climatological_ensemble_bs.loc[:, ~df_climatological_ensemble_bs.columns.str.contains('^Unnamed')]\n",
    "df_climatological_ensemble_bs = df_climatological_ensemble_bs.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the climatological\n",
    "# ensemble.\n",
    "time_column_name_climatological_ensemble_bs = df_climatological_ensemble_bs.columns[0]\n",
    "var_column_name_climatological_ensemble_bs = df_climatological_ensemble_bs.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Name of skill measure of the climatological ensemble: ')\n",
    "print(var_column_name_climatological_ensemble_bs)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_climatological_ensemble_bs)\n",
    "print('Dataframe containing the timeseries of the skill measure of the climatological ensemble: ')\n",
    "df_climatological_ensemble_bs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the bs values of the S2S reforecast ensemble and the QRF predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one timeseries of the prediction's bs and remove any unnamed columns as well as the\n",
    "# index column.\n",
    "df_prediction_bs_14d = read_in_csv_data(config['PATHs_prediction_bs'][0], config['ifiles_prediction_bs_14d'][0])\n",
    "df_prediction_bs_14d = df_prediction_bs_14d.loc[:, ~df_prediction_bs_14d.columns.str.contains('^Unnamed')]\n",
    "df_prediction_bs_14d = df_prediction_bs_14d.drop(['index'], axis =1 )\n",
    "\n",
    "df_prediction_bs_21d = read_in_csv_data(config['PATHs_prediction_bs'][0], config['ifiles_prediction_bs_21d'][0])\n",
    "df_prediction_bs_21d = df_prediction_bs_21d.loc[:, ~df_prediction_bs_21d.columns.str.contains('^Unnamed')]\n",
    "df_prediction_bs_21d = df_prediction_bs_21d.drop(['index'], axis =1 )\n",
    "\n",
    "df_prediction_bs_28d = read_in_csv_data(config['PATHs_prediction_bs'][0], config['ifiles_prediction_bs_28d'][0])\n",
    "df_prediction_bs_28d = df_prediction_bs_28d.loc[:, ~df_prediction_bs_28d.columns.str.contains('^Unnamed')]\n",
    "df_prediction_bs_28d = df_prediction_bs_28d.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the predictions.\n",
    "time_column_name_prediction_bs = df_prediction_bs_14d.columns[0]\n",
    "var_column_name_prediction_bs = df_prediction_bs_14d.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Name of skill measure of the prediction: ')\n",
    "print(var_column_name_prediction_bs)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_prediction_bs)\n",
    "print('Dataframe containing the timeseries of the skill measure of the predictions: ')\n",
    "df_prediction_bs_14d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the dates from the ground truth which are present in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the evaluation period from the ground truth at a lead time of 14d.\n",
    "start_evaluation_period = datetime(config['start_year_of_first_winter'], config['start_month_winter'], config['start_day_winter'])\n",
    "end_evaluation_period = datetime(config['start_year_of_last_winter']+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "df_ground_truth_14d = truncate_data_by_date(df_ground_truth_14d, time_column_name_ground_truth, start_evaluation_period.strftime('%Y_%m_%d'), end_evaluation_period.strftime('%Y_%m_%d')) \n",
    "df_ground_truth_21d = truncate_data_by_date(df_ground_truth_21d, time_column_name_ground_truth, start_evaluation_period.strftime('%Y_%m_%d'), end_evaluation_period.strftime('%Y_%m_%d')) \n",
    "df_ground_truth_28d = truncate_data_by_date(df_ground_truth_28d, time_column_name_ground_truth, start_evaluation_period.strftime('%Y_%m_%d'), end_evaluation_period.strftime('%Y_%m_%d')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the predictions and the ground truth_14d data.\n",
    "joint_dates = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_ground_truth_14d[time_column_name_ground_truth])):\n",
    "    if df_ground_truth_14d[time_column_name_ground_truth].iloc[i].strftime('%Y-%m-%d') == df_prediction_bs_14d[time_column_name_prediction_bs].iloc[l]:\n",
    "        joint_dates.append(df_ground_truth_14d[time_column_name_ground_truth].iloc[i])\n",
    "        l = l+1\n",
    "        if l>len(df_prediction_bs_14d[time_column_name_prediction_bs])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates.append(np.nan)\n",
    "\n",
    "# Append these dates to the dataframe containing the ground truth_14d data.\n",
    "df_ground_truth_14d['joint_dates'] = joint_dates\n",
    "df_ground_truth_14d = df_ground_truth_14d.dropna()\n",
    "df_ground_truth_14d = df_ground_truth_14d.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append these dates to the dataframe containing the ground truth_21d data.\n",
    "df_ground_truth_21d['joint_dates'] = joint_dates\n",
    "df_ground_truth_21d = df_ground_truth_21d.dropna()\n",
    "df_ground_truth_21d = df_ground_truth_21d.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append these dates to the dataframe containing the ground truth_28d data.\n",
    "df_ground_truth_28d['joint_dates'] = joint_dates\n",
    "df_ground_truth_28d = df_ground_truth_28d.dropna()\n",
    "df_ground_truth_28d = df_ground_truth_28d.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the dates from the climatological ensemble which are present in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the dates which are also present in the predeictions.\n",
    "df_climatological_ensemble_bs['joint_dates'] = joint_dates\n",
    "df_climatological_ensemble_bs = df_climatological_ensemble_bs.dropna()\n",
    "df_climatological_ensemble_bs = df_climatological_ensemble_bs.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the dates from the weather regime data which are present in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 00 UTC as S2S reforecasts, and therefore also the predictions, have a daily resolution.\n",
    "start_year_evaluation_period = datetime(2000,1,1)\n",
    "end_year_evaluation_period = datetime(2020,12,31)\n",
    "\n",
    "df_weather_regimes = truncate_data_by_date(df_weather_regimes, time_column_name_weather_regimes, start_year_evaluation_period.strftime('%Y_%m_%d'), end_year_evaluation_period.strftime('%Y_%m_%d'))\n",
    "\n",
    "df_weather_regimes = df_weather_regimes.where(df_weather_regimes['time'] == '00:00:00')\n",
    "df_weather_regimes = df_weather_regimes.dropna()\n",
    "df_weather_regimes = df_weather_regimes.drop('time', axis=1)\n",
    "\n",
    "df_weather_regimes_14d = df_weather_regimes\n",
    "df_weather_regimes_21d = df_weather_regimes\n",
    "df_weather_regimes_28d = df_weather_regimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the predictions and the weather regime data, considering the lead time of data.\n",
    "# Combine the WR present at Initialization with the valid date of the forecasts.\n",
    "joint_dates_wr_14d = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_weather_regimes[time_column_name_weather_regimes])):\n",
    "    \n",
    "    predictions_without_lead_time_14d = pd.to_datetime(df_prediction_bs_14d[time_column_name_prediction_bs].iloc[l])\n",
    "    predictions_without_lead_time_14d = predictions_without_lead_time_14d - timedelta(days=config['lead_time'][0])\n",
    "    \n",
    "    if df_weather_regimes[time_column_name_weather_regimes].iloc[i].strftime('%Y-%m-%d') == predictions_without_lead_time_14d.strftime('%Y-%m-%d'):\n",
    "        joint_dates_wr_14d.append(df_weather_regimes[time_column_name_weather_regimes].iloc[i] + timedelta(days=config['lead_time'][0]))\n",
    "        l = l+1\n",
    "        if l>len(df_prediction_bs_14d[time_column_name_prediction_bs])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates_wr_14d.append(np.nan)\n",
    "\n",
    "# Append these dates to the dataframe containing the weather regimes.\n",
    "df_weather_regimes_14d['date_plus_lead_time'] = joint_dates_wr_14d\n",
    "df_weather_regimes_14d = df_weather_regimes_14d.rename(columns={'WR': 'WR_Initialization'})\n",
    "time_column_name_weather_regimes_14d = 'date_plus_lead_time'\n",
    "df_weather_regimes_14d = df_weather_regimes_14d.dropna()\n",
    "df_weather_regimes_14d = df_weather_regimes_14d.drop(['date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the predictions and the weather regime data, considering the lead time of data.\n",
    "# Combine the WR present at Initialization with the valid date of the forecasts.\n",
    "joint_dates_wr_21d = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_weather_regimes[time_column_name_weather_regimes])):\n",
    "    \n",
    "    predictions_without_lead_time_21d = pd.to_datetime(df_prediction_bs_21d[time_column_name_prediction_bs].iloc[l])\n",
    "    predictions_without_lead_time_21d = predictions_without_lead_time_21d - timedelta(days=config['lead_time'][1])\n",
    "    \n",
    "    if df_weather_regimes[time_column_name_weather_regimes].iloc[i].strftime('%Y-%m-%d') == predictions_without_lead_time_21d.strftime('%Y-%m-%d'):\n",
    "        joint_dates_wr_21d.append(df_weather_regimes[time_column_name_weather_regimes].iloc[i] + timedelta(days=config['lead_time'][1]))\n",
    "        l = l+1\n",
    "        if l>len(df_prediction_bs_21d[time_column_name_prediction_bs])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates_wr_21d.append(np.nan)\n",
    "\n",
    "# Append these dates to the dataframe containing the weather regimes.\n",
    "df_weather_regimes_21d['date_plus_lead_time'] = joint_dates_wr_21d\n",
    "df_weather_regimes_21d = df_weather_regimes_21d.rename(columns={'WR': 'WR_Initialization'})\n",
    "time_column_name_weather_regimes_21d = 'date_plus_lead_time'\n",
    "df_weather_regimes_21d = df_weather_regimes_21d.dropna()\n",
    "df_weather_regimes_21d = df_weather_regimes_21d.drop(['date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the predictions and the weather regime data, considering the lead time of data.\n",
    "# Combine the WR present at Initialization with the valid date of the forecasts.\n",
    "joint_dates_wr_28d = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_weather_regimes[time_column_name_weather_regimes])):\n",
    "    \n",
    "    predictions_without_lead_time_28d = pd.to_datetime(df_prediction_bs_28d[time_column_name_prediction_bs].iloc[l])\n",
    "    predictions_without_lead_time_28d = predictions_without_lead_time_28d - timedelta(days=config['lead_time'][2])\n",
    "    \n",
    "    if df_weather_regimes[time_column_name_weather_regimes].iloc[i].strftime('%Y-%m-%d') == predictions_without_lead_time_28d.strftime('%Y-%m-%d'):\n",
    "        joint_dates_wr_28d.append(df_weather_regimes[time_column_name_weather_regimes].iloc[i] + timedelta(days=config['lead_time'][2]))\n",
    "        l = l+1\n",
    "        if l>len(df_prediction_bs_28d[time_column_name_prediction_bs])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates_wr_28d.append(np.nan)\n",
    "\n",
    "# Append these dates to the dataframe containing the weather regimes.\n",
    "df_weather_regimes_28d['date_plus_lead_time'] = joint_dates_wr_28d\n",
    "df_weather_regimes_28d = df_weather_regimes_28d.rename(columns={'WR': 'WR_Initialization'})\n",
    "time_column_name_weather_regimes_28d = 'date_plus_lead_time'\n",
    "df_weather_regimes_28d = df_weather_regimes_28d.dropna()\n",
    "df_weather_regimes_28d = df_weather_regimes_28d.drop(['date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create meaningful labels for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before plotting, the information about the models which should be shown in the plot's legend\n",
    "# are converted to a nice-looking string by creating the line-breaks set in the configuration \n",
    "# file.\n",
    "list_str_input_info_for_plot_label_prediction_bs = []\n",
    "\n",
    "str_input_info_for_plot_label_benchmark = config['input_data_label_climatological_ensemble']\n",
    "str_input_info_for_plot_label_benchmark = str_input_info_for_plot_label_benchmark.replace('|', '\\n')\n",
    "\n",
    "for i in range(len(config['input_data_labels_prediction_bs'])):\n",
    "    str_input_info_for_plot_label_prediction_bs = config['input_data_labels_prediction_bs'][i]\n",
    "    list_str_input_info_for_plot_label_prediction_bs.append(str_input_info_for_plot_label_prediction_bs.replace('|', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the 20-winter mean bss and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the evaluation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the bs is separated by winter and from these, from these the wintermean bss calculated.\n",
    "bs_climatological_ensemble = []\n",
    "bss_respective_winter_14d = []\n",
    "bss_timeseries_14d = []\n",
    "\n",
    "# Calculate the bss for every year separately.\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "    \n",
    "    # Calculate the mean bs of the climatological ensemble for every winter.\n",
    "    df_climatological_ensemble_respective_winter = truncate_data_by_date(df_climatological_ensemble_bs, time_column_name_climatological_ensemble_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))     \n",
    "    df_climatological_ensemble_respective_winter_mean = np.nanmean(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    bs_climatological_ensemble.append(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    # Calculate the winter mean bs for each of the predictions separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_14d'])):\n",
    "        df_prediction_bs_14d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_14d'][k])\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.loc[:, ~df_prediction_bs_14d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.drop(['index'], axis =1 )\n",
    "        \n",
    "        # For the QRF models trained solely on reanalysis data, extract only the dates which are also present in the\n",
    "        # predictions of the QRF models using S2S reforecasts as input.\n",
    "        if k>8:\n",
    "            df_prediction_bs_14d['joint_dates'] = joint_dates\n",
    "            df_prediction_bs_14d = df_prediction_bs_14d.dropna()\n",
    "            df_prediction_bs_14d = df_prediction_bs_14d.drop(['joint_dates'], axis=1)\n",
    "        \n",
    "        # Extract the respective winter from the predictions and calculate the winter mean bs.\n",
    "        df_prediction_respective_winter_14d = truncate_data_by_date(df_prediction_bs_14d, time_column_name_prediction_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))                 \n",
    "        \n",
    "        df_prediction_respective_winter_mean_14d = np.nanmean(df_prediction_respective_winter_14d[var_column_name_prediction_bs])\n",
    "        \n",
    "        # Calculate the winter mean bss of the respective prediction with respect to the climatological ensemble.\n",
    "        bss_respective_winter_14d.append(1-(df_prediction_respective_winter_mean_14d/df_climatological_ensemble_respective_winter_mean))\n",
    "    \n",
    "    # Combine the winter mean bss in a list.\n",
    "    bss_timeseries_14d.append(bss_respective_winter_14d)\n",
    "    bss_respective_winter_14d = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean bss values over all winters are calculated as the mean of the winterwise bss values and plotted for \n",
    "# the S2S reforecast ensemble and the QRF models with respect to the climatological ensemble in a bar plot.\n",
    "longterm_bss_14d = []\n",
    "longterm_std_bss_14d = []\n",
    "\n",
    "list_str_input_info = []\n",
    "list_str_number_of_model = []\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "\n",
    "# Calculate for every predicting model the 20-winter mean bss separately.\n",
    "for m in range(len(config['ifiles_prediction_bs_14d'])):\n",
    "    longterm_bss_14d.append(np.mean(np.array(bss_timeseries_14d)[:,m])) \n",
    "    longterm_std_bss_14d.append(np.std(np.array(bss_timeseries_14d)[:,m]))\n",
    "    list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[m])\n",
    "    list_str_number_of_model.append(str(m+1))\n",
    "\n",
    "# Plot the 20-winter mean bss as a bar plot.    \n",
    "fig,ax = plt.subplots()\n",
    "plt.axhline(y=0, color='grey', alpha=0.5)\n",
    "plt.axvline(x=0.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8.5, color='grey',linestyle='--', alpha=0.5)\n",
    "\n",
    "bars = plt.bar(np.arange(len(config['ifiles_prediction_bs_14d'])), np.array(longterm_bss_14d), yerr=longterm_std_bss_14d, ecolor='grey', capsize=5, color=color_list, alpha=0.8, tick_label=list_str_number_of_model)\n",
    "\n",
    "ax.bar_label(bars, fmt='%.3f', padding=2)\n",
    "\n",
    "plt.ylim(-0.6, 0.6) \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), ha='center')\n",
    "plt.ylabel('BSS')\n",
    "ax.set_title(str(config['lead_time'][0])+'d lead', ha='right', x=1)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][0])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the bs is separated by winter and from these, from these the wintermean bss calculated.\n",
    "bs_climatological_ensemble = []\n",
    "bss_respective_winter_21d = []\n",
    "bss_timeseries_21d = []\n",
    "\n",
    "# Calculate the bss for every year separately.\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "    \n",
    "    # Calculate the mean bs of the climatological ensemble for every winter.\n",
    "    df_climatological_ensemble_respective_winter = truncate_data_by_date(df_climatological_ensemble_bs, time_column_name_climatological_ensemble_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))     \n",
    "    df_climatological_ensemble_respective_winter_mean = np.nanmean(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    bs_climatological_ensemble.append(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    # Calculate the winter mean bs for each of the predictions separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_21d'])):\n",
    "        df_prediction_bs_21d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_21d'][k])\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.loc[:, ~df_prediction_bs_21d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.drop(['index'], axis =1 )\n",
    "        \n",
    "        # For the QRF models trained solely on reanalysis data, extract only the dates which are also present in the\n",
    "        # predictions of the QRF models using S2S reforecasts as input.\n",
    "        if k>8:\n",
    "            df_prediction_bs_21d['joint_dates'] = joint_dates\n",
    "            df_prediction_bs_21d = df_prediction_bs_21d.dropna()\n",
    "            df_prediction_bs_21d = df_prediction_bs_21d.drop(['joint_dates'], axis=1)\n",
    "        \n",
    "        # Extract the respective winter from the predictions and calculate the winter mean bs.\n",
    "        df_prediction_respective_winter_21d = truncate_data_by_date(df_prediction_bs_21d, time_column_name_prediction_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))                 \n",
    "        \n",
    "        df_prediction_respective_winter_mean_21d = np.nanmean(df_prediction_respective_winter_21d[var_column_name_prediction_bs])\n",
    "        \n",
    "        # Calculate the winter mean bss of the respective prediction with respect to the climatological ensemble.\n",
    "        bss_respective_winter_21d.append(1-(df_prediction_respective_winter_mean_21d/df_climatological_ensemble_respective_winter_mean))\n",
    "    \n",
    "    # Combine the winter mean bss in a list.\n",
    "    bss_timeseries_21d.append(bss_respective_winter_21d)\n",
    "    bss_respective_winter_21d = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean bss values over all winters are calculated as the mean of the winterwise bss values and plotted for \n",
    "# the S2S reforecast ensemble and the QRF models with respect to the climatological ensemble in a bar plot.\n",
    "longterm_bss_21d = []\n",
    "longterm_std_bss_21d = []\n",
    "\n",
    "list_str_input_info = []\n",
    "list_str_number_of_model = []\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "\n",
    "# Calculate for every predicting model the 20-winter mean bss separately.\n",
    "for m in range(len(config['ifiles_prediction_bs_21d'])):\n",
    "    longterm_bss_21d.append(np.mean(np.array(bss_timeseries_21d)[:,m])) \n",
    "    longterm_std_bss_21d.append(np.std(np.array(bss_timeseries_21d)[:,m]))\n",
    "    list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[m])\n",
    "    list_str_number_of_model.append(str(m+1))\n",
    "\n",
    "# Plot the 20-winter mean bss as a bar plot.    \n",
    "fig,ax = plt.subplots()\n",
    "plt.axhline(y=0, color='grey', alpha=0.5)\n",
    "plt.axvline(x=0.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8.5, color='grey',linestyle='--', alpha=0.5)\n",
    "\n",
    "bars = plt.bar(np.arange(len(config['ifiles_prediction_bs_21d'])), np.array(longterm_bss_21d), yerr=longterm_std_bss_21d, ecolor='grey', capsize=5, color=color_list, alpha=0.8, tick_label=list_str_number_of_model)\n",
    "\n",
    "ax.bar_label(bars, fmt='%.3f', padding=2)\n",
    "\n",
    "plt.ylim(-0.6, 0.6) \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), ha='center')\n",
    "plt.ylabel('BSS')\n",
    "ax.set_title(str(config['lead_time'][1])+'d lead', ha='right', x=1)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][1])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the bs is separated by winter and from these, from these the wintermean bss calculated.\n",
    "bs_climatological_ensemble = []\n",
    "bss_respective_winter_28d = []\n",
    "bss_timeseries_28d = []\n",
    "\n",
    "# Calculate the bss for every year separately.\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "    \n",
    "    # Calculate the mean bs of the climatological ensemble for every winter.\n",
    "    df_climatological_ensemble_respective_winter = truncate_data_by_date(df_climatological_ensemble_bs, time_column_name_climatological_ensemble_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))     \n",
    "    df_climatological_ensemble_respective_winter_mean = np.nanmean(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    bs_climatological_ensemble.append(df_climatological_ensemble_respective_winter[var_column_name_climatological_ensemble_bs])\n",
    "    \n",
    "    # Calculate the winter mean bs for each of the predictions separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_28d'])):\n",
    "        df_prediction_bs_28d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_28d'][k])\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.loc[:, ~df_prediction_bs_28d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.drop(['index'], axis =1 )\n",
    "        \n",
    "        # For the QRF models trained solely on reanalysis data, extract only the dates which are also present in the\n",
    "        # predictions of the QRF models using S2S reforecasts as input.\n",
    "        if k>8:\n",
    "            df_prediction_bs_28d['joint_dates'] = joint_dates\n",
    "            df_prediction_bs_28d = df_prediction_bs_28d.dropna()\n",
    "            df_prediction_bs_28d = df_prediction_bs_28d.drop(['joint_dates'], axis=1)\n",
    "        \n",
    "        # Extract the respective winter from the predictions and calculate the winter mean bs.\n",
    "        df_prediction_respective_winter_28d = truncate_data_by_date(df_prediction_bs_28d, time_column_name_prediction_bs, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))                 \n",
    "        \n",
    "        df_prediction_respective_winter_mean_28d = np.nanmean(df_prediction_respective_winter_28d[var_column_name_prediction_bs])\n",
    "        \n",
    "        # Calculate the winter mean bss of the respective prediction with respect to the climatological ensemble.\n",
    "        bss_respective_winter_28d.append(1-(df_prediction_respective_winter_mean_28d/df_climatological_ensemble_respective_winter_mean))\n",
    "    \n",
    "    # Combine the winter mean bss in a list.\n",
    "    bss_timeseries_28d.append(bss_respective_winter_28d)\n",
    "    bss_respective_winter_28d = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean bss values over all winters are calculated as the mean of the winterwise bss values and plotted for \n",
    "# the S2S reforecast ensemble and the QRF models with respect to the climatological ensemble in a bar plot.\n",
    "longterm_bss_28d = []\n",
    "longterm_std_bss_28d = []\n",
    "\n",
    "list_str_input_info = []\n",
    "list_str_number_of_model = []\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "\n",
    "# Calculate for every predicting model the 20-winter mean bss separately.\n",
    "for m in range(len(config['ifiles_prediction_bs_28d'])):\n",
    "    longterm_bss_28d.append(np.mean(np.array(bss_timeseries_28d)[:,m])) \n",
    "    longterm_std_bss_28d.append(np.std(np.array(bss_timeseries_28d)[:,m]))\n",
    "    list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[m])\n",
    "    list_str_number_of_model.append(str(m+1))\n",
    "\n",
    "# Plot the 20-winter mean bss as a bar plot.    \n",
    "fig,ax = plt.subplots()\n",
    "plt.axhline(y=0, color='grey', alpha=0.5)\n",
    "plt.axvline(x=0.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4.5, color='grey',linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8.5, color='grey',linestyle='--', alpha=0.5)\n",
    "\n",
    "bars = plt.bar(np.arange(len(config['ifiles_prediction_bs_28d'])), np.array(longterm_bss_28d), yerr=longterm_std_bss_28d, ecolor='grey', capsize=5, color=color_list, alpha=0.8, tick_label=list_str_number_of_model)\n",
    "\n",
    "ax.bar_label(bars, fmt='%.3f', padding=2)\n",
    "\n",
    "plt.ylim(-0.6, 0.6) \n",
    "plt.setp(ax.xaxis.get_majorticklabels(), ha='center')\n",
    "plt.ylabel('BSS')\n",
    "ax.set_title(str(config['lead_time'][2])+'d lead', ha='right', x=1)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][2])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the weather regime sorted bss and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dates by weather regimes_14d at the initialization date.\n",
    "regime_names = ['AT', 'ScTr', 'ZO', 'AR', 'EuBL', 'GL', 'ScBL', 'No']\n",
    "dates_regimes_14d = []\n",
    "\n",
    "df_regime_1 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[0])\n",
    "df_regime_1 = df_regime_1.dropna()\n",
    "dates_regimes_14d.append(df_regime_1['date_plus_lead_time'])\n",
    "\n",
    "df_regime_2 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[1])\n",
    "df_regime_2 = df_regime_2.dropna()\n",
    "dates_regimes_14d.append(df_regime_2['date_plus_lead_time'])\n",
    "\n",
    "df_regime_3 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[2])\n",
    "df_regime_3 = df_regime_3.dropna()\n",
    "dates_regimes_14d.append(df_regime_3['date_plus_lead_time'])\n",
    "\n",
    "df_regime_4 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[3])\n",
    "df_regime_4 = df_regime_4.dropna()\n",
    "dates_regimes_14d.append(df_regime_4['date_plus_lead_time'])\n",
    "\n",
    "df_regime_5 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[4])\n",
    "df_regime_5 = df_regime_5.dropna()\n",
    "dates_regimes_14d.append(df_regime_5['date_plus_lead_time'])\n",
    "\n",
    "df_regime_6 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[5])\n",
    "df_regime_6 = df_regime_6.dropna()\n",
    "dates_regimes_14d.append(df_regime_6['date_plus_lead_time'])\n",
    "\n",
    "df_regime_7 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[6])\n",
    "df_regime_7= df_regime_7.dropna()\n",
    "dates_regimes_14d.append(df_regime_7['date_plus_lead_time'])\n",
    "\n",
    "df_regime_8 = df_weather_regimes_14d.where(df_weather_regimes_14d['WR_Initialization'] == regime_names[7])\n",
    "df_regime_8 = df_regime_8.dropna()\n",
    "dates_regimes_14d.append(df_regime_8['date_plus_lead_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dates by weather regimes_21d at the initialization date.\n",
    "dates_regimes_21d = []\n",
    "\n",
    "df_regime_1 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[0])\n",
    "df_regime_1 = df_regime_1.dropna()\n",
    "dates_regimes_21d.append(df_regime_1['date_plus_lead_time'])\n",
    "\n",
    "df_regime_2 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[1])\n",
    "df_regime_2 = df_regime_2.dropna()\n",
    "dates_regimes_21d.append(df_regime_2['date_plus_lead_time'])\n",
    "\n",
    "df_regime_3 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[2])\n",
    "df_regime_3 = df_regime_3.dropna()\n",
    "dates_regimes_21d.append(df_regime_3['date_plus_lead_time'])\n",
    "\n",
    "df_regime_4 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[3])\n",
    "df_regime_4 = df_regime_4.dropna()\n",
    "dates_regimes_21d.append(df_regime_4['date_plus_lead_time'])\n",
    "\n",
    "df_regime_5 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[4])\n",
    "df_regime_5 = df_regime_5.dropna()\n",
    "dates_regimes_21d.append(df_regime_5['date_plus_lead_time'])\n",
    "\n",
    "df_regime_6 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[5])\n",
    "df_regime_6 = df_regime_6.dropna()\n",
    "dates_regimes_21d.append(df_regime_6['date_plus_lead_time'])\n",
    "\n",
    "df_regime_7 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[6])\n",
    "df_regime_7= df_regime_7.dropna()\n",
    "dates_regimes_21d.append(df_regime_7['date_plus_lead_time'])\n",
    "\n",
    "df_regime_8 = df_weather_regimes_21d.where(df_weather_regimes_21d['WR_Initialization'] == regime_names[7])\n",
    "df_regime_8 = df_regime_8.dropna()\n",
    "dates_regimes_21d.append(df_regime_8['date_plus_lead_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dates by weather regimes_28d at the initialization date.\n",
    "dates_regimes_28d = []\n",
    "\n",
    "df_regime_1 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[0])\n",
    "df_regime_1 = df_regime_1.dropna()\n",
    "dates_regimes_28d.append(df_regime_1['date_plus_lead_time'])\n",
    "\n",
    "df_regime_2 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[1])\n",
    "df_regime_2 = df_regime_2.dropna()\n",
    "dates_regimes_28d.append(df_regime_2['date_plus_lead_time'])\n",
    "\n",
    "df_regime_3 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[2])\n",
    "df_regime_3 = df_regime_3.dropna()\n",
    "dates_regimes_28d.append(df_regime_3['date_plus_lead_time'])\n",
    "\n",
    "df_regime_4 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[3])\n",
    "df_regime_4 = df_regime_4.dropna()\n",
    "dates_regimes_28d.append(df_regime_4['date_plus_lead_time'])\n",
    "\n",
    "df_regime_5 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[4])\n",
    "df_regime_5 = df_regime_5.dropna()\n",
    "dates_regimes_28d.append(df_regime_5['date_plus_lead_time'])\n",
    "\n",
    "df_regime_6 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[5])\n",
    "df_regime_6 = df_regime_6.dropna()\n",
    "dates_regimes_28d.append(df_regime_6['date_plus_lead_time'])\n",
    "\n",
    "df_regime_7 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[6])\n",
    "df_regime_7= df_regime_7.dropna()\n",
    "dates_regimes_28d.append(df_regime_7['date_plus_lead_time'])\n",
    "\n",
    "df_regime_8 = df_weather_regimes_28d.where(df_weather_regimes_28d['WR_Initialization'] == regime_names[7])\n",
    "df_regime_8 = df_regime_8.dropna()\n",
    "dates_regimes_28d.append(df_regime_8['date_plus_lead_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_14d = []\n",
    "\n",
    "for l in range(len(dates_regimes_14d)):\n",
    "    \n",
    "    dates_specific_regime_14d = dates_regimes_14d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_14d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_14d'])):\n",
    "        \n",
    "        df_prediction_bs_14d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_14d'][k])\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.loc[:, ~df_prediction_bs_14d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_14d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_14d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_14d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_14d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_14d.append(dates_specific_regime_14d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_14d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_14d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_14d['joint_dates_wr'] = joint_dates_wr_14d\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.dropna()\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_14d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_14d = np.mean(df_prediction_bs_14d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_14d.append(1-(mean_bs_predictions_14d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_14d.append(regimemean_bss_14d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_21d = []\n",
    "\n",
    "for l in range(len(dates_regimes_21d)):\n",
    "    \n",
    "    dates_specific_regime_21d = dates_regimes_21d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_21d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_21d'])):\n",
    "        \n",
    "        df_prediction_bs_21d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_21d'][k])\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.loc[:, ~df_prediction_bs_21d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_21d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_21d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_21d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_21d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_21d.append(dates_specific_regime_21d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_21d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_21d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_21d['joint_dates_wr'] = joint_dates_wr_21d\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.dropna()\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_21d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_21d = np.mean(df_prediction_bs_21d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_21d.append(1-(mean_bs_predictions_21d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_21d.append(regimemean_bss_21d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_28d = []\n",
    "\n",
    "for l in range(len(dates_regimes_28d)):\n",
    "    \n",
    "    dates_specific_regime_28d = dates_regimes_28d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_28d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_28d'])):\n",
    "        \n",
    "        df_prediction_bs_28d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_28d'][k])\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.loc[:, ~df_prediction_bs_28d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_28d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_28d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_28d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_28d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_28d.append(dates_specific_regime_28d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_28d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_28d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_28d['joint_dates_wr'] = joint_dates_wr_28d\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.dropna()\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_28d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_28d = np.mean(df_prediction_bs_28d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_28d.append(1-(mean_bs_predictions_28d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_28d.append(regimemean_bss_28d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the regime means of all lead times into one list.\n",
    "regimemeans_all_lead_times = [regimemean_bss_all_regimes_14d, regimemean_bss_all_regimes_21d, regimemean_bss_all_regimes_28d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the list for easier plotting.\n",
    "regimemeans_all_lead_times = np.transpose(regimemeans_all_lead_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regime mean bss.\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "marker_list=['o', 'X', 'X', 'X', 'X', 'd', 'd', 'd', 'd', 's', 's', 's']\n",
    "\n",
    "for l in range(len(regime_names)):\n",
    "    fig = plt.subplots()\n",
    "    for k in range(len(regimemeans_all_lead_times)):\n",
    "        if k==0:\n",
    "            plt.plot(regimemeans_all_lead_times[k][l], marker=marker_list[k], color=color_list[k])\n",
    "        if k==3:\n",
    "            plt.plot(regimemeans_all_lead_times[k][l], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "        if k==8:\n",
    "            plt.plot(regimemeans_all_lead_times[k][l], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "        if k ==10:\n",
    "            plt.plot(regimemeans_all_lead_times[k][l], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "        else:\n",
    "            plt.plot(regimemeans_all_lead_times[k][l], marker=marker_list[k], color=color_list[k], linestyle='', alpha=0.25)\n",
    "        \n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    plt.xticks(range(len(config['lead_time'])), config['lead_time'], size='small')\n",
    "    \n",
    "    plt.ylim(-0.45, 0.45) \n",
    "    plt.ylabel('BSS')\n",
    "    plt.xlabel('Lead Time in Days')\n",
    "    plt.title(regime_names[l]+' Regime', ha='left', x=-0)\n",
    "    plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble_all_lead_times_'+regime_names[l]+'.png', bbox_inches='tight')\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_14d = []\n",
    "\n",
    "for l in range(len(dates_regimes_14d)):\n",
    "    \n",
    "    dates_specific_regime_14d = dates_regimes_14d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_14d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_14d'])):\n",
    "        \n",
    "        df_prediction_bs_14d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_14d'][k])\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.loc[:, ~df_prediction_bs_14d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_14d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_14d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_14d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_14d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_14d.append(dates_specific_regime_14d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_14d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_14d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_14d['joint_dates_wr'] = joint_dates_wr_14d\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.dropna()\n",
    "        df_prediction_bs_14d = df_prediction_bs_14d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_14d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_14d = np.mean(df_prediction_bs_14d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_14d.append(1-(mean_bs_predictions_14d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_14d.append(regimemean_bss_14d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_21d = []\n",
    "\n",
    "for l in range(len(dates_regimes_21d)):\n",
    "    \n",
    "    dates_specific_regime_21d = dates_regimes_21d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_21d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_21d'])):\n",
    "        \n",
    "        df_prediction_bs_21d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_21d'][k])\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.loc[:, ~df_prediction_bs_21d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_21d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_21d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_21d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_21d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_21d.append(dates_specific_regime_21d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_21d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_21d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_21d['joint_dates_wr'] = joint_dates_wr_21d\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.dropna()\n",
    "        df_prediction_bs_21d = df_prediction_bs_21d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_21d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_21d = np.mean(df_prediction_bs_21d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_21d.append(1-(mean_bs_predictions_21d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_21d.append(regimemean_bss_21d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bss is calculated for the predicted models in respect to the climatological ensemble and\n",
    "# plotted sorted by the weather regime present at initialization as bar plots.\n",
    "\n",
    "# Calculate the bss of each weather regime present at initalization sepatately.\n",
    "regimemean_bss_all_regimes_28d = []\n",
    "\n",
    "for l in range(len(dates_regimes_28d)):\n",
    "    \n",
    "    dates_specific_regime_28d = dates_regimes_28d[l]\n",
    "    regime_name = regime_names[l]\n",
    "    \n",
    "    regimemean_bss_28d = []\n",
    "\n",
    "    list_str_input_info = []\n",
    "    list_str_number_of_model = []\n",
    "\n",
    "    # Calcualte the bss of every predicting model separately.\n",
    "    for k in range(len(config['ifiles_prediction_bs_28d'])):\n",
    "        \n",
    "        df_prediction_bs_28d = read_in_csv_data(config['PATHs_prediction_bs'][k], config['ifiles_prediction_bs_28d'][k])\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.loc[:, ~df_prediction_bs_28d.columns.str.contains('^Unnamed')]\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.drop(['index'], axis =1 )\n",
    "                \n",
    "        # Find the dates which are present in the specifc regime and the predictions.\n",
    "        joint_dates_wr_28d = []\n",
    "        m = 0\n",
    "\n",
    "        for i in range(len(df_prediction_bs_28d[time_column_name_prediction_bs])):\n",
    "            if dates_specific_regime_28d.iloc[m].strftime('%Y-%m-%d') == df_prediction_bs_28d[time_column_name_prediction_bs][i]:\n",
    "                joint_dates_wr_28d.append(dates_specific_regime_28d.iloc[m])\n",
    "                m = m+1\n",
    "                if m>len(dates_specific_regime_28d)-1:\n",
    "                    m = 0\n",
    "            else:\n",
    "                joint_dates_wr_28d.append(np.nan)\n",
    "        \n",
    "        df_prediction_bs_28d['joint_dates_wr'] = joint_dates_wr_28d\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.dropna()\n",
    "        df_prediction_bs_28d = df_prediction_bs_28d.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Only extract the bs of the climatological ensemble once per WR.\n",
    "        if k == 0: \n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_bs\n",
    "            df_climatological_ensemble_one_regime['joint_dates_wr'] = joint_dates_wr_28d\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.dropna()\n",
    "            df_climatological_ensemble_one_regime = df_climatological_ensemble_one_regime.drop(['joint_dates_wr'], axis=1)\n",
    "        \n",
    "        # Calculate the regime mean bs of the predictions and the climatological ensemble.\n",
    "        mean_bs_predictions_28d = np.mean(df_prediction_bs_28d['BS'])\n",
    "        mean_bs_climatological_ensemble = np.mean(df_climatological_ensemble_one_regime['BS'])\n",
    "        \n",
    "        # Calculate the regime mean bss.\n",
    "        regimemean_bss_28d.append(1-(mean_bs_predictions_28d/mean_bs_climatological_ensemble))\n",
    "         \n",
    "        # Collect information to be shown on the plot.    \n",
    "        list_str_input_info.append(list_str_input_info_for_plot_label_prediction_bs[k])\n",
    "        list_str_number_of_model.append(str(k+1))\n",
    "        \n",
    "    regimemean_bss_all_regimes_28d.append(regimemean_bss_28d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regime mean bss.\n",
    "regimemean_bss_all_regimes_14d = np.transpose(regimemean_bss_all_regimes_14d)\n",
    "\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "marker_list=['o', 'X', 'X', 'X', 'X', 'd', 'd', 'd', 'd', 's', 's', 's']\n",
    "\n",
    "fig = plt.subplots()\n",
    "for k in range(len(regimemean_bss_all_regimes_14d)):\n",
    "    if k==0:\n",
    "        plt.plot(regimemean_bss_all_regimes_14d[k], marker=marker_list[k], color=color_list[k])\n",
    "    if k==3:\n",
    "        plt.plot(regimemean_bss_all_regimes_14d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k==8:\n",
    "        plt.plot(regimemean_bss_all_regimes_14d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k ==10:\n",
    "        plt.plot(regimemean_bss_all_regimes_14d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    else:\n",
    "        plt.plot(regimemean_bss_all_regimes_14d[k], marker=marker_list[k], color=color_list[k], linestyle='', alpha=0.25)\n",
    "        \n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xticks(range(len(regime_names)), regime_names, size='small')\n",
    "    \n",
    "plt.ylim(-0.45, 0.45) \n",
    "plt.ylabel('BSS')\n",
    "plt.xlabel('WR at Initialization')\n",
    "plt.title(str(config['lead_time'][0])+'d lead', ha='left', x=-0)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][0])+'d_all_regimes.png', bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regime mean bss.\n",
    "regimemean_bss_all_regimes_21d = np.transpose(regimemean_bss_all_regimes_21d)\n",
    "\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "marker_list=['o', 'X', 'X', 'X', 'X', 'd', 'd', 'd', 'd', 's', 's', 's']\n",
    "\n",
    "fig = plt.subplots()\n",
    "for k in range(len(regimemean_bss_all_regimes_21d)):\n",
    "    if k==0:\n",
    "        plt.plot(regimemean_bss_all_regimes_21d[k], marker=marker_list[k], color=color_list[k])\n",
    "    if k==3:\n",
    "        plt.plot(regimemean_bss_all_regimes_21d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k==8:\n",
    "        plt.plot(regimemean_bss_all_regimes_21d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k ==10:\n",
    "        plt.plot(regimemean_bss_all_regimes_21d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    else:\n",
    "        plt.plot(regimemean_bss_all_regimes_21d[k], marker=marker_list[k], color=color_list[k], linestyle='', alpha=0.25)\n",
    "        \n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xticks(range(len(regime_names)), regime_names, size='small')\n",
    "    \n",
    "plt.ylim(-0.45, 0.45) \n",
    "plt.ylabel('BSS')\n",
    "plt.xlabel('WR at Initialization')\n",
    "plt.title(str(config['lead_time'][1])+'d lead', ha='left', x=-0)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][1])+'d_all_regimes.png', bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regime mean bss.\n",
    "regimemean_bss_all_regimes_28d = np.transpose(regimemean_bss_all_regimes_28d)\n",
    "\n",
    "color_list=['goldenrod', 'peru', 'saddlebrown', 'gold', 'khaki', 'darkgrey', 'silver', 'slategrey', 'lightsteelblue', 'purple', 'darkblue', 'green']\n",
    "marker_list=['o', 'X', 'X', 'X', 'X', 'd', 'd', 'd', 'd', 's', 's', 's']\n",
    "\n",
    "fig = plt.subplots()\n",
    "for k in range(len(regimemean_bss_all_regimes_28d)):\n",
    "    if k==0:\n",
    "        plt.plot(regimemean_bss_all_regimes_28d[k], marker=marker_list[k], color=color_list[k])\n",
    "    if k==3:\n",
    "        plt.plot(regimemean_bss_all_regimes_28d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k==8:\n",
    "        plt.plot(regimemean_bss_all_regimes_28d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    if k ==10:\n",
    "        plt.plot(regimemean_bss_all_regimes_28d[k], marker=marker_list[k], color=color_list[k], linestyle='--')\n",
    "    else:\n",
    "        plt.plot(regimemean_bss_all_regimes_28d[k], marker=marker_list[k], color=color_list[k], linestyle='', alpha=0.25)\n",
    "        \n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xticks(range(len(regime_names)), regime_names, size='small')\n",
    "    \n",
    "plt.ylim(-0.45, 0.45) \n",
    "plt.ylabel('BSS')\n",
    "plt.xlabel('WR at Initialization')\n",
    "plt.title(str(config['lead_time'][2])+'d lead', ha='left', x=-0)\n",
    "plt.savefig(config['PATH_plots']+'BSS_'+config['binary_ground_truth']+'_'+config['rfc_model_names']+'_and_climatological_ensemble'+'_lead_'+str(config['lead_time'][2])+'d_all_regimes.png', bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a standalone legend for the plot visualizing the BS difference of the RFC\n",
    "# predictions and the climatological ensemble.\n",
    "first_line = plt.Line2D([], [], marker=marker_list[0], color=color_list[0], linestyle='-', alpha=1, label=list_str_number_of_model[0]+': '+list_str_input_info_for_plot_label_prediction_bs[0])\n",
    "second_line = plt.Line2D([], [], marker=marker_list[1], color=color_list[1], linestyle=' ', alpha=0.25, label=list_str_number_of_model[1]+': '+list_str_input_info_for_plot_label_prediction_bs[1])\n",
    "third_line = plt.Line2D([], [], marker=marker_list[2], color=color_list[2], linestyle=' ', alpha=0.25, label=list_str_number_of_model[2]+': '+list_str_input_info_for_plot_label_prediction_bs[2])\n",
    "fourth_line = plt.Line2D([], [], marker=marker_list[3], color=color_list[3], linestyle='--', alpha=1, label=list_str_number_of_model[3]+': '+list_str_input_info_for_plot_label_prediction_bs[3])\n",
    "fifth_line = plt.Line2D([], [], marker=marker_list[4], color=color_list[4], linestyle=' ', alpha=0.25, label=list_str_number_of_model[4]+': '+list_str_input_info_for_plot_label_prediction_bs[4])\n",
    "sixth_line = plt.Line2D([], [], marker=marker_list[5], color=color_list[5], linestyle=' ', alpha=0.25, label=list_str_number_of_model[5]+': '+list_str_input_info_for_plot_label_prediction_bs[5])\n",
    "seventh_line = plt.Line2D([], [], marker=marker_list[6], color=color_list[6], linestyle=' ', alpha=0.25, label=list_str_number_of_model[6]+': '+list_str_input_info_for_plot_label_prediction_bs[6])\n",
    "eightth_line = plt.Line2D([], [], marker=marker_list[7], color=color_list[7], linestyle='', alpha=0.25, label=list_str_number_of_model[7]+': '+list_str_input_info_for_plot_label_prediction_bs[7])\n",
    "nineth_line = plt.Line2D([], [], marker=marker_list[8], color=color_list[8], linestyle='--', alpha=1, label=list_str_number_of_model[8]+': '+list_str_input_info_for_plot_label_prediction_bs[8])\n",
    "tenth_line = plt.Line2D([], [], marker=marker_list[9], color=color_list[9], linestyle=' ', alpha=0.25, label=list_str_number_of_model[9]+': '+list_str_input_info_for_plot_label_prediction_bs[9])\n",
    "eleventh_line = plt.Line2D([], [], marker=marker_list[10], color=color_list[10], linestyle='--', alpha=1, label=list_str_number_of_model[10]+': '+list_str_input_info_for_plot_label_prediction_bs[10])\n",
    "twelveth_line = plt.Line2D([], [], marker=marker_list[11], color=color_list[11], linestyle=' ', alpha=0.25, label=list_str_number_of_model[11]+': '+list_str_input_info_for_plot_label_prediction_bs[11])\n",
    "\n",
    "\n",
    "plt.legend(handles=[first_line, second_line, third_line, fourth_line, fifth_line, sixth_line, seventh_line, eightth_line, nineth_line, tenth_line, eleventh_line, twelveth_line,], ncol=1)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_colorbar_for_bss_lineplot_half_textwidth_long.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a standalone legend for the plot visualizing the BS difference of the RFC predictions and the \n",
    "# climatological ensemble.\n",
    "first_line = plt.Line2D([], [], marker=marker_list[0], color=color_list[0], linestyle='-', alpha=1, label=list_str_number_of_model[0]+': '+list_str_input_info_for_plot_label_prediction_bs[0])\n",
    "second_line = plt.Line2D([], [], marker=marker_list[1], color=color_list[1], linestyle=' ', alpha=0.25, label=list_str_number_of_model[1]+': '+list_str_input_info_for_plot_label_prediction_bs[1])\n",
    "third_line = plt.Line2D([], [], marker=marker_list[2], color=color_list[2], linestyle=' ', alpha=0.25, label=list_str_number_of_model[2]+': '+list_str_input_info_for_plot_label_prediction_bs[2])\n",
    "fourth_line = plt.Line2D([], [], marker=marker_list[3], color=color_list[3], linestyle='--', alpha=1, label=list_str_number_of_model[3]+': '+list_str_input_info_for_plot_label_prediction_bs[3])\n",
    "fifth_line = plt.Line2D([], [], marker=marker_list[4], color=color_list[4], linestyle=' ', alpha=0.25, label=list_str_number_of_model[4]+': '+list_str_input_info_for_plot_label_prediction_bs[4])\n",
    "sixth_line = plt.Line2D([], [], marker=marker_list[5], color=color_list[5], linestyle=' ', alpha=0.25, label=list_str_number_of_model[5]+': '+list_str_input_info_for_plot_label_prediction_bs[5])\n",
    "seventh_line = plt.Line2D([], [], marker=marker_list[6], color=color_list[6], linestyle=' ', alpha=0.25, label=list_str_number_of_model[6]+': '+list_str_input_info_for_plot_label_prediction_bs[6])\n",
    "eightth_line = plt.Line2D([], [], marker=marker_list[7], color=color_list[7], linestyle='', alpha=0.25, label=list_str_number_of_model[7]+': '+list_str_input_info_for_plot_label_prediction_bs[7])\n",
    "nineth_line = plt.Line2D([], [], marker=marker_list[8], color=color_list[8], linestyle='--', alpha=1, label=list_str_number_of_model[8]+': '+list_str_input_info_for_plot_label_prediction_bs[8])\n",
    "tenth_line = plt.Line2D([], [], marker=marker_list[9], color=color_list[9], linestyle='', alpha=0.25, label=list_str_number_of_model[9]+': '+list_str_input_info_for_plot_label_prediction_bs[9])\n",
    "eleventh_line = plt.Line2D([], [], marker=marker_list[10], color=color_list[10], linestyle='--', alpha=1, label=list_str_number_of_model[10]+': '+list_str_input_info_for_plot_label_prediction_bs[10])\n",
    "twelveth_line = plt.Line2D([], [], marker=marker_list[11], color=color_list[11], linestyle=' ', alpha=0.25, label=list_str_number_of_model[11]+': '+list_str_input_info_for_plot_label_prediction_bs[11])\n",
    "\n",
    "\n",
    "plt.legend(handles=[first_line, second_line, third_line, fourth_line, fifth_line, sixth_line, seventh_line, eightth_line, nineth_line, tenth_line, eleventh_line, twelveth_line,], ncol=4)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_colorbar_for_bss_lineplot_textwidth_long.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a compact standalone legend for the bar plot visualizing the BSS.\n",
    "first_filling = mpatches.Patch(color=color_list[0], label=list_str_number_of_model[0]+': '+list_str_input_info[0])\n",
    "second_filling = mpatches.Patch(color=color_list[1], label=list_str_number_of_model[1]+': '+list_str_input_info[1])\n",
    "third_filling = mpatches.Patch(color=color_list[2], label=list_str_number_of_model[2]+': '+list_str_input_info[2])\n",
    "fourth_filling = mpatches.Patch(color=color_list[3], label=list_str_number_of_model[3]+': '+list_str_input_info[3])\n",
    "fifth_filling = mpatches.Patch(color=color_list[4], label=list_str_number_of_model[4]+': '+list_str_input_info[4])\n",
    "sixth_filling = mpatches.Patch(color=color_list[5], label=list_str_number_of_model[5]+': '+list_str_input_info[5])\n",
    "seventh_filling = mpatches.Patch(color=color_list[6], label=list_str_number_of_model[6]+': '+list_str_input_info[6])\n",
    "eightth_filling = mpatches.Patch(color=color_list[7], label=list_str_number_of_model[7]+': '+list_str_input_info[7])\n",
    "nineth_filling = mpatches.Patch(color=color_list[8], label=list_str_number_of_model[8]+': '+list_str_input_info[8])\n",
    "tenth_filling = mpatches.Patch(color=color_list[9], label=list_str_number_of_model[9]+': '+list_str_input_info[9])\n",
    "eleventh_filling = mpatches.Patch(color=color_list[10], label=list_str_number_of_model[10]+': '+list_str_input_info[10])\n",
    "twelveth_filling = mpatches.Patch(color=color_list[11], label=list_str_number_of_model[11]+': '+list_str_input_info[11])\n",
    "\n",
    "plt.legend(handles=[first_filling, second_filling, third_filling, fourth_filling, fifth_filling, sixth_filling, seventh_filling, eightth_filling, nineth_filling, tenth_filling, eleventh_filling, twelveth_filling], ncol=1)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_legend_for_bss_bar_plot_half_textwidth_long.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a compact standalone legend for the bar plot visualizing the BSS.\n",
    "first_filling = mpatches.Patch(color=color_list[0], label=list_str_number_of_model[0]+': '+list_str_input_info[0])\n",
    "second_filling = mpatches.Patch(color=color_list[1], label=list_str_number_of_model[1]+': '+list_str_input_info[1])\n",
    "third_filling = mpatches.Patch(color=color_list[2], label=list_str_number_of_model[2]+': '+list_str_input_info[2])\n",
    "fourth_filling = mpatches.Patch(color=color_list[3], label=list_str_number_of_model[3]+': '+list_str_input_info[3])\n",
    "fifth_filling = mpatches.Patch(color=color_list[4], label=list_str_number_of_model[4]+': '+list_str_input_info[4])\n",
    "sixth_filling = mpatches.Patch(color=color_list[5], label=list_str_number_of_model[5]+': '+list_str_input_info[5])\n",
    "seventh_filling = mpatches.Patch(color=color_list[6], label=list_str_number_of_model[6]+': '+list_str_input_info[6])\n",
    "eightth_filling = mpatches.Patch(color=color_list[7], label=list_str_number_of_model[7]+': '+list_str_input_info[7])\n",
    "nineth_filling = mpatches.Patch(color=color_list[8], label=list_str_number_of_model[8]+': '+list_str_input_info[8])\n",
    "tenth_filling = mpatches.Patch(color=color_list[9], label=list_str_number_of_model[9]+': '+list_str_input_info[9])\n",
    "eleventh_filling = mpatches.Patch(color=color_list[10], label=list_str_number_of_model[10]+': '+list_str_input_info[10])\n",
    "twelveth_filling = mpatches.Patch(color=color_list[11], label=list_str_number_of_model[11]+': '+list_str_input_info[11])\n",
    "\n",
    "plt.legend(handles=[first_filling, second_filling, third_filling, fourth_filling, fifth_filling, sixth_filling, seventh_filling, eightth_filling, nineth_filling, tenth_filling, eleventh_filling, twelveth_filling], ncol=3)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_legend_for_bss_bar_plot_whole_textwidth_long.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
