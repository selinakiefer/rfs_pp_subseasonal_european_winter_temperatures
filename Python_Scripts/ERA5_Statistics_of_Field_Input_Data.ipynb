{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating \"Statistics of field\" from the Meteorological Predictor Fields as Input for RF-based ML-Models\n",
    "Version 18 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "continuous timeseries of meteorological predictors as 2d-fields in csv-format\n",
    "### Output: csv-file\n",
    "continuous timeseries of the minimum, mean, maximum and variance of the meteorological predictors per date in csv-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the paths' and files' names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed path and file names.\n",
    "PATH_defined_functions = './Defined_Functions/'\n",
    "\n",
    "PATH_input_data = './Data_in_csv_Format/'\n",
    "ifiles_input_data = ['era5_u10_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z100_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z250_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z500_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_t850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_H850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_u300_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_msl_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14.csv']\n",
    "\n",
    "PATH_output_file = './Data_in_csv_Format/'\n",
    "file_name_output_file = 'era5_statistics_u10_z100_z250_60W_60E_20N_80N_1950_2020_lead_time_14d.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions.\n",
    "import sys\n",
    "sys.path.insert(1,PATH_defined_functions)\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  List the predictors to be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the desired predictors and set how many of these should be taken from the first \n",
    "# dataframe. From all other dataframes, only 1 predictor is taken (if more are needed, list\n",
    "# these input files multiple times in \"ifiles_input_data\"). It is necessary to take the time as\n",
    "# a predictor since the data will be grouped by date later.\n",
    "desired_predictors = ['time', 'month', 'u10', 'z100', 'z250', 'z500', 'z850', 't850', 'H850', 'u300', 'msl']\n",
    "number_of_predictors_in_first_dataframe = 3\n",
    "time_column_name = 'time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all predictors into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe is created and the desired predictors from the first data file are written\n",
    "# into it.\n",
    "df_combined_input_data = pd.DataFrame()\n",
    "df_input_data = read_in_csv_data(PATH_input_data, ifiles_input_data[0])\n",
    "for i in range(number_of_predictors_in_first_dataframe):\n",
    "    df_combined_input_data[desired_predictors[i]] = df_input_data [desired_predictors[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From all other dataframes, the specified predictor is added to this new dataframe.\n",
    "for k in range(len(ifiles_input_data)-1):\n",
    "    df_input_data = read_in_csv_data(PATH_input_data, ifiles_input_data[k+1])\n",
    "    df_combined_input_data[desired_predictors[i+k+1]] = df_input_data [desired_predictors[i+k+1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the statistics (minimum, mean, maximum and variance) of the predictor fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the time is set as the index and the data is grouped by date. For every desired statistic\n",
    "# of the field, the calculation is done directly after the grouping and written as separate\n",
    "# pandas series. Here, the minimum, mean, maximum and variance are calculated.\n",
    "df_combined_input_data[time_column_name] = pd.to_datetime(df_combined_input_data[time_column_name])\n",
    "df_combined_input_data = df_combined_input_data.set_index(time_column_name)\n",
    "ds_input_data_grouped_min = df_combined_input_data.groupby([df_combined_input_data.index.year, df_combined_input_data.index.month, df_combined_input_data.index.day], as_index=False).min()\n",
    "ds_input_data_grouped_mean = df_combined_input_data.groupby([df_combined_input_data.index.year, df_combined_input_data.index.month, df_combined_input_data.index.day], as_index=False).mean()\n",
    "ds_input_data_grouped_max = df_combined_input_data.groupby([df_combined_input_data.index.year, df_combined_input_data.index.month, df_combined_input_data.index.day], as_index=False).max()\n",
    "ds_input_data_grouped_var = df_combined_input_data.groupby([df_combined_input_data.index.year, df_combined_input_data.index.month, df_combined_input_data.index.day], as_index=False).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe is created combining all statistics and naming them uniquely.\n",
    "df_statistics = pd.DataFrame()\n",
    "for l in range(len(desired_predictors)-1):\n",
    "    df_statistics['min_'+desired_predictors[l+1]] = ds_input_data_grouped_min[desired_predictors[l+1]]\n",
    "    df_statistics['mean_'+desired_predictors[l+1]] = ds_input_data_grouped_mean[desired_predictors[l+1]]\n",
    "    df_statistics['max_'+desired_predictors[l+1]] = ds_input_data_grouped_max[desired_predictors[l+1]]   \n",
    "    df_statistics['var_'+desired_predictors[l+1]] = ds_input_data_grouped_var[desired_predictors[l+1]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the statistics (a single scalar value for each day) of the month are senseless, one of\n",
    "# the columns is renamed simply with 'month' and the others are removed.\n",
    "df_statistics = df_statistics.rename(columns={'mean_month':'month'})\n",
    "df_statistics = df_statistics.drop(['min_month', 'max_month', 'var_month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the time information again to the reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the time got lost by using .groupby(), a separate new dataframe is created containing\n",
    "# only the time. To this dataframe, three new columns are added containing the year, month and \n",
    "# day.\n",
    "df_combined_input_data = df_combined_input_data.reset_index()\n",
    "df_time = pd.DataFrame()\n",
    "df_time[time_column_name] = pd.to_datetime(df_combined_input_data[time_column_name])\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "df_time['year'] = df_time.index.year\n",
    "df_time['month'] = df_time.index.month\n",
    "df_time['day'] = df_time.index.day\n",
    "df_time = df_time.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new dataframe is then grouped by date and 'averaged' resulting in a daily time-\n",
    "# series but separated into year, month and day.\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "ds_time_mean = df_time.groupby([df_time.index.year, df_time.index.month, df_time.index.day], as_index=False).mean().astype(int).astype(str) \n",
    "df_time_mean = pd.DataFrame(ds_time_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The separated timeseries is now combined into a single daily timeseries (nothing needs to be\n",
    "# changed here).\n",
    "daily_timeseries = (df_time_mean['year'].astype(str)+'-'+df_time_mean['month'].astype(str)+'-'+df_time_mean['day']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next step, the time is added to the dataframe containing the statistics as predictors \n",
    "# (nothing needs to be changed here).\n",
    "df_statistics.insert(0, time_column_name, daily_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublecheck the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is reshaped and sorted correctly.\n",
    "df_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if everything is sorted, renamed or removed correctly at the end of the\n",
    "# dataframe.\n",
    "df_statistics.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in csv-format.\n",
    "df_statistics.to_csv(PATH_output_file+file_name_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
