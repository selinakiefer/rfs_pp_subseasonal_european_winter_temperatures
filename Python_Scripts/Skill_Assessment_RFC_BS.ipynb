{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the Skill of a RFC Model with the Brier Score (BS)\n",
    "Version 22 January 2024, Selina Kiefer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "predictions of the Random Forest Classifier Models as binary timeseries of cold wave days in csv-format, binary timeseries of cold wave days in csv-format\n",
    "### Output: csv-file, png-files\n",
    "continuous timeseries of daily BS values in csv-format and plotted in png-format as well as the prediction of the RFC plotted together with the ground truth in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions and configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configurations/'\n",
    "ifile_configurations = 'Configurations_Skill_Assessment_RFC_with_BS.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import*\n",
    "from create_auxiliary_date import *\n",
    "from apply_cold_wave_definition_smid_et_al_2019 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file.\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions and remove any unnamed columns as well as the index column.\n",
    "df_predictions = read_in_csv_data(config['PATH_predictions'], config['ifile_predictions'])\n",
    "df_predictions = df_predictions.loc[:, ~df_predictions.columns.str.contains('^Unnamed')]\n",
    "df_predictions = df_predictions.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the predictions.\n",
    "time_column_name_predictions = df_predictions.columns[0]\n",
    "var_column_name_predictions = df_predictions.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Names of predictions done by the ML model: ')\n",
    "print(var_column_name_predictions)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_predictions)\n",
    "print('Dataframe containing the predictions: ')\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ground truth and remove any unnamed columns as well as the index column.\n",
    "df_ground_truth = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth'])\n",
    "df_ground_truth = df_ground_truth.loc[:, ~df_ground_truth.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth = df_ground_truth.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Ground truth to compare the predictions with: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the dates from the ground truth which are present in the S2S reforecast ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the evaluation period from the ground truth.\n",
    "start_evaluation_period = datetime(config['start_year_of_first_winter'], config['start_month_winter'], config['start_day_winter'])\n",
    "end_evaluation_period = datetime(config['start_year_of_last_winter']+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "df_ground_truth = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_evaluation_period.strftime('%Y_%m_%d'), end_evaluation_period.strftime('%Y_%m_%d')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the S2S reforecasts ensemble and the ground truth data.\n",
    "joint_dates = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_ground_truth[time_column_name_ground_truth])):\n",
    "    if df_ground_truth[time_column_name_ground_truth].iloc[i].strftime('%Y-%m-%d') == df_predictions[time_column_name_predictions].iloc[l]:\n",
    "        joint_dates.append(df_ground_truth[time_column_name_ground_truth].iloc[i])\n",
    "        l = l+1\n",
    "        if l>len(df_predictions[time_column_name_predictions])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append these dates to the dataframe containing the ground truth data.\n",
    "df_ground_truth['joint_dates'] = joint_dates\n",
    "df_ground_truth = df_ground_truth.dropna()\n",
    "df_ground_truth = df_ground_truth.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the RFC predictions and the ground truth for the skill assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the evaluation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, the predictions of each year are extracted and saved to a list. The same is\n",
    "# done for the ground truth. The respective forecast dates of each year are also saved to a \n",
    "# list. \n",
    "all_winters_list_cold_waves_ground_truth = []\n",
    "all_winters_list_cold_waves_predictions = []\n",
    "forecast_dates = []\n",
    "\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "        \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "    df_ground_truth_respective_winter = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "    df_predictions_respective_winter = truncate_data_by_date(df_predictions, time_column_name_predictions, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))   \n",
    "\n",
    "    all_winters_list_cold_waves_ground_truth.append(df_ground_truth_respective_winter[var_column_name_ground_truth])\n",
    "    all_winters_list_cold_waves_predictions.append(df_predictions_respective_winter[var_column_name_predictions])\n",
    "    \n",
    "    forecast_dates.append(pd.to_datetime(df_ground_truth_respective_winter[time_column_name_ground_truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of the BS between the ground truth and the RFC predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the daily BS is computed and saved to a list. Furthermore, the forecast time is saved in\n",
    "# continuous form to a list.\n",
    "forecast_time = []\n",
    "bs_daily_one_year = []\n",
    "bs = []\n",
    "bs_winterwise = []\n",
    "\n",
    "for k in range(len(start_years_of_winter)):\n",
    "    forecast_time.extend(forecast_dates[k])\n",
    "    bs_one_year = 0\n",
    "    bs_daily_one_year = []\n",
    "    for l in range(len(all_winters_list_cold_waves_predictions[k])):\n",
    "        bs_daily = (all_winters_list_cold_waves_predictions[k][l]-all_winters_list_cold_waves_ground_truth[k][l])**2\n",
    "        bs_daily_one_year.append(bs_daily)\n",
    "    bs.extend(np.array(bs_daily_one_year))\n",
    "    bs_winterwise.append(np.array(bs_daily_one_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, a dataframe containing the daily BS values and the corresponding forecasting times is\n",
    "# created. \n",
    "df_skill_measure_bs = pd.DataFrame()\n",
    "df_skill_measure_bs['time'] = forecast_time\n",
    "df_skill_measure_bs['BS'] = np.array(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the BS values in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pandas dataframe containing the BS values is saved in csv format. \n",
    "df_skill_measure_bs.to_csv(config['PATH_statistics']+config['model_name']+'_BS_ground_truth_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the RFC predictions together with the ground truth and the BS for a plausibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before plotting, the information about the input data which should be shown in the plot title\n",
    "# is converted to a nice-looking string by creating the line-breaks set in the configuration \n",
    "# file.\n",
    "str_input_info_for_plot_titles = config['input_data_title']\n",
    "str_input_info_for_plot_titles = str_input_info_for_plot_titles.replace('|', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For illustration purposes, the fraction of ensemble members of the RFC predicting a cold wave\n",
    "# days is plotted with the cold waves in the ground truth. This gives a first impression about \n",
    "# the model's forecast skill.\n",
    "for i in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[i], all_winters_list_cold_waves_ground_truth[i], color='k', linestyle='--', label='Ground Truth')\n",
    "    plt.plot(forecast_dates[i], all_winters_list_cold_waves_predictions[i], marker='o', linestyle='', color='b', alpha=0.6, label='Predictions')    \n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel(var_column_name_predictions)\n",
    "    plt.title(config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[i])+'_'+str(start_years_of_winter[i]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BS values for each winter are plotted separately. In combination with the plot above a first plausibility\n",
    "# check is possible. The lower the BS value, the more similar the prediction of the RFC and the ground truth \n",
    "# have to be.\n",
    "for n in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[n], bs_winterwise[n], color='b', marker='o', markersize=4, linestyle='--')\n",
    "    plt.axhline(y=np.nanmean(bs_winterwise[n]), color='grey', linestyle='--', label='Wintermean')\n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel('BS')\n",
    "    plt.title('Daily BS of '+config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_BS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[n])+'_'+str(start_years_of_winter[n]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the CRPS for all winters in the evaluation period for a quick overview of the forecasting performance of the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the daily BS values is plotted for all winters in the evaluation period. \n",
    "plt.plot(forecast_time, bs, marker='s', linestyle='', markersize=2, color='b')\n",
    "plt.xlabel(time_column_name_ground_truth)\n",
    "plt.ylabel('BS')\n",
    "plt.title('Daily BS of '+config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "plt.savefig(config['PATH_plots']+config['model_name']+'_BS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
