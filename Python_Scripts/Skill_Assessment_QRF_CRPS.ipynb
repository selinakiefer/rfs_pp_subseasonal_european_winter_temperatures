{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the Skill of a QRF Model with the Continuous Ranked Probability Score (CRPS)\n",
    "Version 22 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "predictions of the Quantile Random Forest models as continuous timeseries of temperature in csv-format,  continuous timeseries of ground truth temperature in csv-format\n",
    "### Output: csv-file, png-files\n",
    "continuous timeseries of daily CRPS values in csv-format and plotted in png-format as well as the prediction of the QRF plotted together with the ground truth in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions and configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configurations/'\n",
    "ifile_configurations = 'Configurations_Skill_Assessment_QRF_with_CRPS.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import properscoring as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import*\n",
    "from create_auxiliary_date import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file.\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions and remove any unnamed columns as well as the index column.\n",
    "df_predictions = read_in_csv_data(config['PATH_predictions'], config['ifile_predictions'])\n",
    "df_predictions = df_predictions.loc[:, ~df_predictions.columns.str.contains('^Unnamed')]\n",
    "df_predictions = df_predictions.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the predictions.\n",
    "time_column_name_predictions = df_predictions.columns[0]\n",
    "var_column_name_predictions = df_predictions.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Names of predictions done by the ML model: ')\n",
    "print(var_column_name_predictions)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_predictions)\n",
    "print('Dataframe containing the predictions: ')\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ground truth and remove any unnamed columns as well as the index column.\n",
    "df_ground_truth = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth'])\n",
    "df_ground_truth = df_ground_truth.loc[:, ~df_ground_truth.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth = df_ground_truth.drop(['index', 'level_0'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Ground truth to compare the predictions with: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the dates from the ground truth which are present in the S2S reforecast ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the evaluation period from the ground truth.\n",
    "start_evaluation_period = datetime(config['start_year_of_first_winter'], config['start_month_winter'], config['start_day_winter'])\n",
    "end_evaluation_period = datetime(config['start_year_of_last_winter']+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "df_ground_truth = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_evaluation_period.strftime('%Y_%m_%d'), end_evaluation_period.strftime('%Y_%m_%d')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates which are present in the S2S reforecasts ensemble and the ground truth data.\n",
    "joint_dates = []\n",
    "l = 0\n",
    "\n",
    "for i in range(len(df_ground_truth[time_column_name_ground_truth])):\n",
    "    if df_ground_truth[time_column_name_ground_truth].iloc[i].strftime('%Y-%m-%d') == df_predictions[time_column_name_predictions].iloc[l]:\n",
    "        joint_dates.append(df_ground_truth[time_column_name_ground_truth].iloc[i])\n",
    "        l = l+1\n",
    "        if l>len(df_predictions[time_column_name_predictions])-1:\n",
    "            l = 0\n",
    "    else:\n",
    "        joint_dates.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append these dates to the dataframe containing the ground truth data.\n",
    "df_ground_truth['joint_dates'] = joint_dates\n",
    "df_ground_truth = df_ground_truth.dropna()\n",
    "df_ground_truth = df_ground_truth.drop(['joint_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the QRF predictions and the ground truth for the skill assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the evaluation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, the predictions of each year are extracted and saved to a list. The same is\n",
    "# done for the ground truth. The respective forecast dates of each year are also saved to a \n",
    "# list. \n",
    "predictions = []\n",
    "ground_truth = []\n",
    "forecast_dates = []\n",
    "\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "    df_ground_truth_respective_winter = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "    df_predictions_respective_winter = truncate_data_by_date(df_predictions, time_column_name_predictions, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d'))   \n",
    "    \n",
    "    predictions_respective_winter = df_predictions_respective_winter.drop([time_column_name_predictions], axis=1)\n",
    "    predictions_respective_winter = np.array(np.squeeze(predictions_respective_winter))\n",
    " \n",
    "    predictions.append(predictions_respective_winter)\n",
    "    \n",
    "    ground_truth.append(df_ground_truth_respective_winter[var_column_name_ground_truth])\n",
    "    forecast_dates.append(pd.to_datetime(df_ground_truth_respective_winter[time_column_name_ground_truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of the CRPS between the ground truth and the QRF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the CRPS between the ground truth data and the QRF forecasts is computed\n",
    "# (ps.crps_ensemble), converted into a dataframe and written into a list. Additionally, a \n",
    "# continuous list of all forecast dates is created.\n",
    "crps = []\n",
    "crps_winterwise = []\n",
    "forecast_time = []\n",
    "\n",
    "for l in range(len(start_years_of_winter)):\n",
    "       \n",
    "    for_crps = ps.crps_ensemble(ground_truth[l], predictions[l]) \n",
    "    df_crps = pd.DataFrame(for_crps)\n",
    "    crps.extend(np.array(df_crps))\n",
    "    crps_winterwise.append(np.array(df_crps))\n",
    "    forecast_time.extend(forecast_dates[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CRPS and the respective forecast dates are combined in a new dataframe. The CRPS values\n",
    "# are rounded for a nicer representation.\n",
    "df_skill_measure_crps = pd.DataFrame()\n",
    "crps = np.round(crps, decimals=2)\n",
    "\n",
    "df_skill_measure_crps['time'] = forecast_time\n",
    "df_skill_measure_crps['CRPS'] = crps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the CRPS values in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the pandas dataframe containing the CRPS values is saved in csv format. \n",
    "df_skill_measure_crps.to_csv(config['PATH_statistics']+config['model_name']+'_CRPS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the QRF predictions together with the ground truth and the CRPS for a plausibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before plotting, the information about the input data which should be shown in the plot title\n",
    "# is converted to a nice-looking string by creating the line-breaks set in the configuration \n",
    "# file.\n",
    "str_input_info_for_plot_titles = config['input_data_title']\n",
    "str_input_info_for_plot_titles = str_input_info_for_plot_titles.replace('|', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For illustration purposes, the median and two in the configuration file defined percentiles of\n",
    "# the predictions are plotted together with the ground truth. This gives a first impression\n",
    "# about the models' forecast skill.\n",
    "for k in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[k], np.median(predictions[k], axis=1), color='b', label='Median of Predictions')\n",
    "    plt.fill_between(x=forecast_dates[k], y1=np.percentile(predictions[k], config['upper_quantile']*100, axis=1), y2=np.percentile(predictions[k], config['lower_quantile']*100, axis=1), color='b', alpha=0.25, label=(str(config['lower_quantile'])+'-'+str(config['upper_quantile'])+' Quantiles of Predictions'))\n",
    "    plt.plot(forecast_dates[k], np.array(np.squeeze(ground_truth[k])), color='k', linestyle='--', label='Ground Truth')\n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel(var_column_name_ground_truth+' in '+config['unit_of_ground_truth_and_predictions'])\n",
    "    plt.title(config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_predictions_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[k])+'_'+str(start_years_of_winter[k]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CRPS values for each winter are plotted separately. In combination with the plot above a first plausibility\n",
    "# check is possible. The lower the CRPS value, the more similar the prediction of the QRF and the ground truth \n",
    "# have to be.\n",
    "for m in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[m], crps_winterwise[m], color='b', marker='o', markersize=4, linestyle='--')\n",
    "    plt.axhline(y=np.nanmean(crps_winterwise[m]), color='grey', linestyle='-', label='Wintermean')\n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel('CRPS in '+config['unit_of_ground_truth_and_predictions'])\n",
    "    plt.title('Daily CRPS of '+config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_CRPS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[m])+'_'+str(start_years_of_winter[m]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the CRPS for all winters in the evaluation period for a quick overview of the forecasting performance of the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the daily CRPS values is plotted for the whole evaluation period.\n",
    "plt.plot(forecast_time, crps, marker='s', linestyle='', markersize=2, color='b')\n",
    "plt.xlabel(time_column_name_ground_truth)\n",
    "plt.ylabel('CRPS in '+config['unit_of_ground_truth_and_predictions'])\n",
    "plt.title('Daily CRPS of '+config['model_name']+' Predictions, Lead Time '+str(config['lead_time'])+'d, \\n Input: '+str_input_info_for_plot_titles)\n",
    "plt.savefig(config['PATH_plots']+config['model_name']+'_timeseries_CRPS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
