{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Binary Ground Truth Cold Wave Days\n",
    "Version 17 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: netcdf- or grib-file and csv-file\n",
    "1. netcdf- or grib-file with ground truth (i.e. E-OBS V23.1e, tg, daily mean, 1950 - 2020, Nov-Apr, 3-20°E and 45-60°N, e.g. from https://www.ecad.eu/download/ensembles/download.php ), or, optionally, directly continuous timeseries of ground truth temperature in csv-format (then skip the part with CDO and start directly with Python)\n",
    "2. threshold temperatures for cold waves in csv-format\n",
    "### Output: csv-file\n",
    "binary timeseries of cold wave days in csv-format (1 = cold wave day, 0 = non cold wave day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used software: Climate Data Operators and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Climate Data Operators (CDO) \n",
    "\n",
    "Tailored open-source software to perform the most-common meteorological operations efficiently (and much faster than Python). \n",
    "\n",
    "Up to date information about CDO: https://code.mpimet.mpg.de/projects/cdo\n",
    "\n",
    "Reference: Schulzweida, U. (2019): \"CDO User Guide\". Available at: https://doi.org/10.5281/ZENODO.3539275."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short introduction to CDO\n",
    "\n",
    "The overall structure for most operations is:\n",
    "\n",
    "cdo -operator_last_executed,optional_specifications -operator_first_executed,optional_specifcations ifile ofile\n",
    "\n",
    "e.g. cdo -daymean -selyear,1950,1951 input_file_name output_file_name\n",
    "\n",
    "The input file (ifile) and the output file (ofile) of one operation have to have different names. So it is best to name all files, which are not intended for further use, similarly, e.g. temp_1, temp_2, etc. and to delete them afterwards directly.\n",
    "\n",
    "CDO does not ask when overwriting an existing file. So make sure that everything is named uniquely and correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with CDO\n",
    "\n",
    "Since it is much faster than Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first, check the data file's content\n",
    "This is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short overview of the data file's content.\n",
    "!cdo sinfov /home/my6406/Desktop/Wissenschaftliche_Mitarbeit/Data_Archive/E_OBS/eobs_v23e_daymean_sellonlatbox_3_20_45_60.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: use a more detailed description of the data file's content. It might be wise to use \n",
    "# a separate terminal for this command since it prints all available information about the data\n",
    "# file. Use grib_dump for files in grib-format, \n",
    "# nc_dump for files in netcdf-format. \n",
    "#! grib_dump ./Data_Archive/E_OBS/eobs_v23e_daymean_sellonlatbox_3_20_45_60.grib\n",
    "! nc_dump ./Data_Archive/E_OBS/eobs_v23e_daymean_sellonlatbox_3_20_45_60.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a gridbox (sellonlatbox,°W,°E,°S,°N). Western longitudes have to be given as \n",
    "# 360°-°W). In case there is only 1 latitude or longitude to average over, select the desired\n",
    "# longitude/latitude and on the second position the desired longitude/latitude+1. Otherwise \n",
    "# CDO may perform not well.    \n",
    "! cdo sellonlatbox,3,20,45,60 ./E_OBS/eobs_v23e_daymean_sellonlatbox_3_20_45_60.nc temp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the areal mean (fldmean) over the desired area chosen above.\n",
    "! cdo fldmean temp_1 temp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of certain times, e.g. only the wintermonths (selmon).\n",
    "! cdo selmon,1,2,3,4,11,12 temp_2 temp_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the lead time from the beginning of the data. \n",
    "# Number of days to delete = lead_time.\n",
    "! cdo delete,day=1,2,3,4,5,6,7,8,9,10,11,12,13,14,month=1,year=1950 temp_3 temp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the time is sorted correctly (sorttimestamp) and the file is named correctly.\n",
    "! cdo sorttimestamp temp_4 ./Data_in_Netcdf_Format/eobsv23e_tg_3E_20E_45N_60N_1950_2020_only_Nov_Apr_lead_time_14d.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from grib-format to netcdf-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the grib-file to a netcdf-file if necessary. The Python-scripts are designed to use\n",
    "# netcdf-files.\n",
    "#! cdo -f nc copy ofile.grib ofile.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary files which have been created by CDO since the names of the input files \n",
    "# and output files have to be unique.\n",
    "#! rm temp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a nice overview of the data, pandas dataframes are used. These are then converted directly into csv-format for storage which ensures a safe and easy data transfer between various jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the paths' and files' names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed path and file names.\n",
    "PATH_defined_functions = './Defined_Functions/'\n",
    "\n",
    "PATH_data = './Data_in_csv_Format/'\n",
    "ifile_data = 'eobsv23e_tg_3E_20E_45N_60N_1950_2020_only_Nov_Apr_14d_lead.csv'\n",
    "\n",
    "PATH_thresholds = './Threshold_Data/'\n",
    "ifile_thresholds = 'cold_wave_thresholds_Smid_et_al_2019_for_1970_2000.csv'\n",
    "\n",
    "PATH_output_file = './Data_in_csv_Format/'\n",
    "file_name_output_file = 'eobsv23e_tg_3E_20E_45N_60N_1950_2020_binary_cold_waves_lead_time_14d.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1,PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from create_auxiliary_date import *\n",
    "from truncate_data_by_date import *\n",
    "from apply_cold_wave_definition_smid_et_al_2019 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the ground truth temperature data and check the file's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ground truth and remove any unnamed columns as well as the index column.\n",
    "df_data = read_in_csv_data(PATH_data,ifile_data)\n",
    "df_data = df_data.loc[:, ~df_data.columns.str.contains('^Unnamed')]\n",
    "df_data = df_data.drop( ['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the dataframe.\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the end of the dataframe.\n",
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name = df_data.columns[0]\n",
    "var_column_name = df_data.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the temperature thresholds of the cold wave criterion and check the file's content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the thresholds for the cold wave index and remove any unnamed columns as well as the\n",
    "# index column.\n",
    "df_thresholds = read_in_csv_data(PATH_thresholds,ifile_thresholds)\n",
    "df_thresholds = df_thresholds.loc[:, ~df_thresholds.columns.str.contains('^Unnamed')]\n",
    "df_thresholds = df_thresholds.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the dataframe containing the cold wave thresholds.\n",
    "df_thresholds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the tail of the dataframe containing the thresholds.\n",
    "df_thresholds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the threshold.\n",
    "time_column_name_thresholds = df_thresholds.columns[0]\n",
    "var_column_name_thresholds = df_thresholds.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the cold wave criterion to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, two different dataframes are created with the threshold for the cold wave \n",
    "# definition. One for regular years and one for leap years. Therefore, the index of the original\n",
    "# dataframe is set to the time and the index of the 29 February is determined. Then, a new \n",
    "# dataframe without the 29 February is created for regular years. The original dataframe is used\n",
    "# for leap years.\n",
    "df_thresholds[time_column_name_thresholds]=pd.to_datetime(df_thresholds[time_column_name_thresholds])\n",
    "df_thresholds = df_thresholds.set_index(time_column_name_thresholds)\n",
    "index_of_february_29 = df_thresholds[((df_thresholds.index.month == 2) & (df_thresholds.index.day == 29))].index\n",
    "df_thresholds_without_29_feb = df_thresholds.drop(index_of_february_29)\n",
    "df_thresholds = df_thresholds.reset_index()\n",
    "df_thresholds_without_29_feb = df_thresholds_without_29_feb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the training period is created.\n",
    "start_years_of_winter = np.arange(1950, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the ground truth timeseries does not start with the beginning of a winter, the beginning\n",
    "#  of the timeseries until the start of the first winter is checked for cold waves. Therefore, the \n",
    "# respective part of the ground truth and the fitting part of the cold wave thresholds are extracted.\n",
    "# Then, the cold wave definition by Smid et al. (2019) is applied and the binary classification\n",
    "# of whether at a specific date a cold wave occurred ('1') or not ('0') is saved to a list. \n",
    "# Also, the dates are saved to a list.\n",
    "dates = []\n",
    "\n",
    "all_winters_list_cold_waves_data = []\n",
    "\n",
    "start_winter = datetime(1950, 2, 1)\n",
    "end_winter = datetime(1950, 4, 30)\n",
    "\n",
    "df_thresholds_start_training_data = truncate_data_by_date(df_thresholds, time_column_name_thresholds, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "threshold_cold_waves = df_thresholds_start_training_data[var_column_name_thresholds]\n",
    "\n",
    "\n",
    "df_data_respective_winter = truncate_data_by_date(df_data, time_column_name, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "\n",
    "df_data_binned = pd.DataFrame()\n",
    "df_data_binned['time'] = df_data_respective_winter[time_column_name]\n",
    "list_cold_waves_data = apply_cold_wave_definition_smid_et_al_2019(df_data_binned, df_data_respective_winter, var_column_name, threshold_cold_waves)\n",
    "          \n",
    "all_winters_list_cold_waves_data.extend(list_cold_waves_data)\n",
    "dates.extend(pd.to_datetime(df_data_respective_winter[time_column_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the same is done for every complete winter in the ground truth timeseries. The cold wave\n",
    "# thresholds are taken depending on whether it is a leap year or not, meaning that the \n",
    "# 29 February is included in the threshold data or not.\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    if calendar.isleap(start_year_of_winter+1):\n",
    "        threshold_cold_waves = df_thresholds[var_column_name_thresholds]\n",
    "    else:\n",
    "        threshold_cold_waves = df_thresholds_without_29_feb[var_column_name_thresholds]\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, 11, 1)\n",
    "    end_winter = datetime(start_year_of_winter+1, 4, 30)\n",
    "\n",
    "    df_data_respective_winter = truncate_data_by_date(df_data, time_column_name, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "\n",
    "    df_data_binned = pd.DataFrame()\n",
    "    df_data_binned['time'] = df_data_respective_winter[time_column_name]\n",
    "    list_cold_waves_data = apply_cold_wave_definition_smid_et_al_2019(df_data_binned, df_data_respective_winter, var_column_name, threshold_cold_waves)\n",
    "          \n",
    "    all_winters_list_cold_waves_data.extend(list_cold_waves_data)\n",
    "\n",
    "    dates.extend(pd.to_datetime(df_data_respective_winter[time_column_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a last step, the procedure is done for the rest of the ground truth timeseries which does\n",
    "# not cover a whole winter anymore.\n",
    "start_winter = datetime(2020, 11, 1)\n",
    "end_winter = datetime(2020, 12, 28)\n",
    "\n",
    "df_thresholds_end_training_data = truncate_data_by_date(df_thresholds, time_column_name_thresholds, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "threshold_cold_waves = df_thresholds_end_training_data[var_column_name_thresholds]\n",
    "\n",
    "\n",
    "df_data_respective_winter = truncate_data_by_date(df_data, time_column_name, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "\n",
    "df_data_binned = pd.DataFrame()\n",
    "df_data_binned['time'] = df_data_respective_winter[time_column_name]\n",
    "list_cold_waves_data = apply_cold_wave_definition_smid_et_al_2019(df_data_binned, df_data_respective_winter, var_column_name, threshold_cold_waves)\n",
    "          \n",
    "all_winters_list_cold_waves_data.extend(list_cold_waves_data)\n",
    "\n",
    "dates.extend(pd.to_datetime(df_data_respective_winter[time_column_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, a new dataframe is created containing the dates of the ground truth and the binary cold\n",
    "# wave index.\n",
    "df_data_binary_cold_waves = pd.DataFrame()\n",
    "df_data_binary_cold_waves['time'] = dates\n",
    "df_data_binary_cold_waves['Cold_Wave'] = all_winters_list_cold_waves_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plausibility check if the application of the cold wave criterion worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is checked whether all dates in the ground truth timeseries have been checked for a\n",
    "# cold wave occurrence.\n",
    "if len(df_data_binary_cold_waves['Cold_Wave']) == len(df_data[var_column_name]):\n",
    "    print('All data has been checked for cold waves.')\n",
    "else:\n",
    "    print('Not all data has been checked for cold waves!')\n",
    "    print('Days to be checked: '+str(len(df_data[var_column_name])))\n",
    "    print('Days actually checked: '+str(len(all_winters_list_cold_waves_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if the cold wave definition has been correctly, it is checked whether a reasonable\n",
    "# number of days with cold waves have been detected in the ground truth timeseries.\n",
    "days_with_cold_waves = 0\n",
    "binary_list_of_cold_waves = df_data_binary_cold_waves['Cold_Wave']\n",
    "for i in range(len(binary_list_of_cold_waves)):\n",
    "    if binary_list_of_cold_waves[i] == 1:\n",
    "        days_with_cold_waves +=1\n",
    "\n",
    "print('There are '+str(days_with_cold_waves)+' days with cold waves from a total of '+str(len(binary_list_of_cold_waves))+' days.')\n",
    "print('This means that '+str(days_with_cold_waves/len(binary_list_of_cold_waves)*100)+'% of the winterdays are cold wave days.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublecheck the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is sorted, renamed or removed correctly.\n",
    "df_data_binary_cold_waves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if everything is sorted, renamed or removed correctly at the end of the\n",
    "# dataframe.\n",
    "df_data_binary_cold_waves.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the binary ground truth cold wave data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in csv-format.\n",
    "df_data_binary_cold_waves.to_csv(PATH_output_file+file_name_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
