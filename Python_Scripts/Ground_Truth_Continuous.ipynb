{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Continuous Ground Truth Temperature\n",
    "Version 17 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: netcdf- or grib-files\n",
    "1. netcdf- or grib-file with ground truth temperature (i.e. E-OBS V23.1e, tg, daily mean, 1950 - 2020, Nov-Apr, 3-20°E and 45-60°N, e.g. from https://www.ecad.eu/download/ensembles/download.php )\n",
    "2. netcdf- or grib-file with elevation data (i.e. E-OBS V23.1e, elevation, 3-20°E and 45-60°N, e.g. from https://www.ecad.eu/download/ensembles/download.php )\n",
    "\n",
    "### Output: csv-file\n",
    "continuous timeseries of ground truth temperature in csv-format (7-day running mean, averaged over 3-20°E and 45-60°N (only grid points on land, one grid point away from coasts and elevation<800m) and adapted to the desired lead time of model intended for forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used software: Climate Data Operators and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Climate Data Operators (CDO) \n",
    "\n",
    "Tailored open-source software to perform the most-common meteorological operations efficiently (and much faster than Python). \n",
    "\n",
    "Up to date information about CDO: https://code.mpimet.mpg.de/projects/cdo\n",
    "\n",
    "Reference: Schulzweida, U. (2019): \"CDO User Guide\". Available at: https://doi.org/10.5281/ZENODO.3539275."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short introduction to CDO\n",
    "\n",
    "The overall structure for most operations is:\n",
    "\n",
    "cdo -operator_last_executed,optional_specifications -operator_first_executed,optional_specifcations ifile ofile\n",
    "\n",
    "e.g. cdo -daymean -selyear,1950,1951 input_file_name output_file_name\n",
    "\n",
    "The input file (ifile) and the output file (ofile) of one operation have to have different names. So it is best to name all files, which are not intended for further use, similarly, e.g. temp_1, temp_2, etc. and to delete them afterwards directly.\n",
    "\n",
    "CDO does not ask when overwriting an existing file. So make sure that everything is named uniquely and correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with CDO\n",
    "\n",
    "Since it is much faster than Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first, check the data files' content \n",
    "This is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short overview of the temperature data file's content.\n",
    "!cdo sinfov ./E_OBS/eobs_tg_mean_v23.1e.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short overview of the elevation data file's content.\n",
    "!cdo sinfov ./E_OBS/eobs_v23e_surface_elevation.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the correct longitude-latitude box (sellonlatbox,°W,°E,°S,°N) for the elevation data. Western longitudes \n",
    "# have to be given as 360°-°W). In case there is only 1 latitude or longitude to average over, select the desired\n",
    "# longitude/latitude and on the second position the desired longitude/latitude+1. Otherwise \n",
    "# CDO may perform not well. \n",
    "! cdo sellonlatbox,3,20,45,60 ./E_OBS/eobs_v23e_surface_elevation.nc ./Data_in_Netcdf_Format/eobsv23e_elevation_sellonlatbox.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a gridbox (sellonlatbox,°W,°E,°S,°N). Western longitudes have to be given as \n",
    "# 360°-°W). In case there is only 1 latitude or longitude to average over, select the desired\n",
    "# longitude/latitude and on the second position the desired longitude/latitude+1. Otherwise \n",
    "# CDO may perform not well.    \n",
    "! cdo sellonlatbox,3,20,45,60 ./E_OBS/eobs_tg_mean_v23.1e.nc temp_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of certain times, e.g. only the winter months (selmon).\n",
    "! cdo selmon,1,2,3,4,11,12 temp_1 temp_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the lead time from the beginning of the data.\n",
    "# Number of days to delete = lead_time.\n",
    "! cdo delete,day=1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,month=1,year=1950 temp_3 temp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the time is sorted correctly (sorttimestamp) and the file is named correctly.\n",
    "! cdo sorttimestamp temp_4 ./Data_in_Netcdf_Format/eobsv23e_tg_3E_20E_45N_60N_1950_2020_only_Nov_Apr_28d_lead.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert from grib-format to netcdf-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the grib-file to a netcdf-file if necessary. The Python-scripts are designed to use\n",
    "# netcdf-files.\n",
    "#! cdo -f nc copy ofile.grib ofile.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary files which have been created by CDO.\n",
    "! rm temp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a nice overview of the data, pandas dataframes are used. These are then converted directly into csv-format for storage which ensures a safe and easy data transfer between various jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the paths' and files' names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed path and file names.\n",
    "PATH_defined_functions = './Defined_Functions/'\n",
    "\n",
    "PATH_data = './Data_in_Netcdf_Format/'\n",
    "ifile_data = 'eobsv23e_tg_3E_20E_45N_60N_1950_2020_only_Nov_Apr_28d_lead.nc'\n",
    "\n",
    "PATH_mask = './Data_in_Netcdf_Format/'\n",
    "ifile_mask = 'eobsv23e_elevation_sellonlatbox.nc'\n",
    "\n",
    "PATH_output_file = './Data_in_csv_Format/'\n",
    "file_name_output_file = 'eobsv23e_tg_3E_20E_45N_60N_1950_2020_only_Nov_Apr_28d_lead.csv'\n",
    "\n",
    "PATH_plots = './Plots/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.morphology import erosion\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions.\n",
    "import sys\n",
    "sys.path.insert(1,PATH_defined_functions)\n",
    "from read_in_netcdf_data import *\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data and check the file's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and show its header.\n",
    "df_data = read_in_netcdf_data(PATH_data, ifile_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the end of the dataframe.\n",
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the mask (aka the elevation data) and show its header.\n",
    "df_mask = read_in_netcdf_data(PATH_mask, ifile_mask)\n",
    "df_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also show the end of the dataframe.\n",
    "df_mask.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a mask to exclude high mountains and coastal areas from the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, convert the relevant data (longitude, latitude and elevation) in separate numpy arrays.\n",
    "df_mask_lon = np.array(df_mask['longitude'])\n",
    "df_mask_lat = np.array(df_mask['latitude'])\n",
    "df_mask_elevation = np.array(df_mask['elevation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to reshape the elevation data into a 2d representation, find out the number of longitudes and latitudes\n",
    "# in the order. To do so, use numpy's unique() which counts all the unique values in an array.\n",
    "number_longitudes = len(np.unique(df_mask_lon))\n",
    "number_latitudes = len(np.unique(df_mask_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into 2d fields.\n",
    "df_mask_elevation = np.reshape(df_mask_elevation, (number_longitudes, number_latitudes))\n",
    "df_mask_lon = np.reshape(df_mask_lon, (number_longitudes, number_latitudes))\n",
    "df_mask_lat = np.reshape(df_mask_lat, (number_longitudes, number_latitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to get a first overview over the different elevations.\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent ((2, 21, 44, 61))\n",
    "ax.coastlines(resolution='50m')\n",
    "bodr = cartopy.feature.NaturalEarthFeature(category='cultural', \n",
    "    name='admin_0_boundary_lines_land', scale='50m', facecolor='none', alpha=0.7)\n",
    "ax.add_feature(bodr, linestyle='--', edgecolor='r', alpha=1)\n",
    "plt.scatter(df_mask_lon, df_mask_lat, c=df_mask_elevation, cmap='copper_r')\n",
    "plt.colorbar(label='Elevation in m')\n",
    "plt.title('E-OBS Elevation, Resolution 0.25°')\n",
    "plt.savefig(PATH_plots+'E_OBS_Elevation_Data.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, create a new binary elevation array in which all non-NaN values are replaced by 1 and all NaN\n",
    "# values (aka the sea grid points) are replaced by 0.\n",
    "df_mask_elevation_binary = df_mask_elevation\n",
    "\n",
    "here_are_non_NaNs = ~np.isnan(df_mask_elevation)\n",
    "df_mask_elevation_binary[here_are_non_NaNs] = 1\n",
    "\n",
    "here_are_NaNs = np.isnan(df_mask_elevation)\n",
    "df_mask_elevation_binary[here_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to exclude the coastal areas from the land, the next grid-point to every sea grid-point should be replaced\n",
    "# by 0 (instead of 1). Therefore, a filter in shape of a cross made out of ones is created.\n",
    "cross=np.zeros((3,3))\n",
    "cross[1,:]=1\n",
    "cross[:,1]=1\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, this filter is applied to the binary land-sea mask using scipy's erosion function.\n",
    "eroded_mask = erosion(df_mask_elevation_binary, cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the eroded data is reshaped to the original shape of the dataframe again. As a sanity check, also the\n",
    "# longitudes and latitudes are reshaped into their original shape again.\n",
    "eroded_mask_reshaped = np.reshape(eroded_mask, (number_longitudes*number_latitudes, 1))\n",
    "lon_mask_reshaped = np.reshape(df_mask_lon, (number_longitudes*number_latitudes, 1))\n",
    "lat_mask_reshaped = np.reshape(df_mask_lat, (number_longitudes*number_latitudes,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reshaped arrays are added to the original dataframe containing the elevation data.\n",
    "df_mask['lon_reshaped'] = lon_mask_reshaped\n",
    "df_mask['lat_reshaped'] = lat_mask_reshaped\n",
    "df_mask['eroded_mask'] = eroded_mask_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To exclude not only the coastal areas from the mask but also the high mountains, only grid-points with an elevation\n",
    "# below 800m are kept (.where()). Then, the NaNs are replaced by 0 to be consistent with the binary elevation mask.\n",
    "df_mask['eroded_mask'] = df_mask['eroded_mask'].where(df_mask['elevation']<800)\n",
    "df_mask['eroded_mask'] = df_mask['eroded_mask'].fillna(0)\n",
    "df_mask = df_mask.drop(['lon_reshaped', 'lat_reshaped'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mask as csv-data.\n",
    "df_mask.to_csv(PATH_output_file+'Mask_for_Defining_Central_Europe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a nice plot showing all remaining elevations, the column containing the elevation data is multiplied with\n",
    "# the column containing the mask. All grid-points which are kept, keep the same value as before, the others are set\n",
    "# to 0 by the multiplication. For a nicer plot, the zeros are replaced by NaNs.\n",
    "df_mask['elevation_mask'] = df_mask['elevation']*df_mask['eroded_mask']\n",
    "df_mask['elevation_mask'] = df_mask['elevation_mask'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining grid-points with their elevation shown is plotted.\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent ((2, 21, 44, 61))\n",
    "ax.coastlines(resolution='50m')\n",
    "bodr = cartopy.feature.NaturalEarthFeature(category='cultural', \n",
    "    name='admin_0_boundary_lines_land', scale='50m', facecolor='none', alpha=0.7)\n",
    "ax.add_feature(bodr, linestyle='--', edgecolor='r', alpha=1)\n",
    "plt.scatter(df_mask['longitude'], df_mask['latitude'], c=df_mask['elevation_mask'], alpha=1, cmap='copper_r')\n",
    "plt.colorbar(label='Elevation in m')\n",
    "plt.title('Elevation of Grid Points in E-OBS Dataset')\n",
    "plt.savefig(PATH_plots+'Masked_E_OBS_Elevation_Data.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the mask to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the mask is binary and the temperature given in °C, an issue with the zeros can occur, since they could be\n",
    "# present in both data but with different meanings. Therefore, the temperature data is converted to Kelvin. Since we\n",
    "# look at surface air temperatures, 0K is not plausible and the problem with the binary mask solved.\n",
    "data = np.array(df_data['tg']) \n",
    "data = data + 273.0\n",
    "df_data['tg'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the mask is static in time, it needs to be applied to every day separately. Therefore, the number of days\n",
    "# has to be determined first.\n",
    "number_of_days = int(len(df_data['tg'])/len(df_mask['eroded_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the mask is repeated accordingly.\n",
    "mask_repeated = []\n",
    "for i in range(number_of_days):\n",
    "    mask_repeated.extend(np.array(df_mask['eroded_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The repeated mask is added to the dataframe containing the temperatures.\n",
    "df_data['eroded_mask'] = mask_repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, the mask is applied to the data by multiplication. Again, the valid values keep their value and the\n",
    "# values which are masked are set to 0 by the multiplication with the binary mask. Since in the next step an areal \n",
    "# mean will be calculated, the zeros are set to NaNs.\n",
    "df_data['mask_applied_to_tg'] = df_data['tg']*df_data['eroded_mask']\n",
    "df_data['mask_applied_to_tg'] = df_data['mask_applied_to_tg'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the areal mean of the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a first step, all rows containing NaNs are dropped. Then, the aerial mean is calculated for every day.\n",
    "df_data = df_data.dropna()\n",
    "df_data_mean = df_data.groupby(df_data['time']).mean()\n",
    "df_data_mean = df_data_mean.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply a 7-day running mean for temporal aggregation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a 7-day rolling mean for temporal aggregation.\n",
    "df_data_mean['tg_rolling_mean'] = df_data_mean['tg'].rolling(window=7, center=True).mean()\n",
    "df_data_mean = df_data_mean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column with the rolling mean to avoid confusion.\n",
    "df_data_mean = df_data_mean.drop(['tg'], axis=1)\n",
    "df_data_mean = df_data_mean.rename(columns={'tg_rolling_mean':'tg'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any columns containing NaN-Values since the used ML-models cannot handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any columns containing NaN-values.\n",
    "df_data_mean = df_data_mean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a minimal, useful representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any unnecessary columns here, e.g. the latitude and longitude for aerial means.\n",
    "df_data_mean = df_data_mean.drop(['longitude', 'latitude', 'eroded_mask', 'mask_applied_to_tg'], axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublecheck the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is sorted, renamed or removed correctly. Note:\n",
    "# Although the data is displayed with wrong extra precision, it is saved correctly in\n",
    "# csv-format later. \n",
    "df_data_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if everything is sorted, renamed or removed correctly at the end of the\n",
    "# dataframe.\n",
    "df_data_mean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in csv-format.\n",
    "df_data_mean.to_csv(PATH_output_file+file_name_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
