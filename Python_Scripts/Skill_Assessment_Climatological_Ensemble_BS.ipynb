{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the Skill of the Climatological Ensemble with the Brier Score (BS)\n",
    "Version 19 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "ensemble of continuous timeseries of ground truth temperature for a winter (e.g. climatological ensemble) in csv-format, binary timeseries of cold wave days in csv-format\n",
    "### Output: csv-file, png-files\n",
    "binary timeseries of cold wave days in the climatological ensemble, continuous timeseries of daily BS values in csv-format in csv-format and plotted in png-format as well as the prediction of the climatological ensemble plotted together with the ground truth in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions and configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configurations/'\n",
    "ifile_configurations = 'Configurations_Skill_Assessment_Climatological_Ensemble_with_BS.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import*\n",
    "from create_auxiliary_date import *\n",
    "from apply_cold_wave_definition_smid_et_al_2019 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file.\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the climatological_ensemble and remove any unnamed columns as well as the index column.\n",
    "df_climatological_ensemble = read_in_csv_data(config['PATH_climatological_ensemble'], config['ifile_climatological_ensemble'])\n",
    "df_climatological_ensemble = df_climatological_ensemble.loc[:, ~df_climatological_ensemble.columns.str.contains('^Unnamed')]\n",
    "df_climatological_ensemble = df_climatological_ensemble.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the climatological_ensemble.\n",
    "time_column_name_climatological_ensemble = df_climatological_ensemble.columns[0]\n",
    "var_column_name_climatological_ensemble = df_climatological_ensemble.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Names of climatological_ensemble done by the ML model: ')\n",
    "print(var_column_name_climatological_ensemble)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_climatological_ensemble)\n",
    "print('Dataframe containing the climatological ensemble: ')\n",
    "df_climatological_ensemble.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ground truth and remove any unnamed columns as well as the index column.\n",
    "df_ground_truth = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth'])\n",
    "df_ground_truth = df_ground_truth.loc[:, ~df_ground_truth.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth = df_ground_truth.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Ground truth to compare the climatological ensemble with: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cold wave thresholds and remove any unnamed columns as well as the index column.\n",
    "df_thresholds = read_in_csv_data(config['PATH_thresholds'], config['ifile_thresholds'])\n",
    "df_thresholds = df_thresholds.loc[:, ~df_thresholds.columns.str.contains('^Unnamed')]\n",
    "df_thresholds = df_thresholds.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the threshold.\n",
    "time_column_name_thresholds = df_thresholds.columns[0]\n",
    "var_column_name_thresholds = df_thresholds.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly.\n",
    "print('Thresholds for cold waves to apply to the climatological ensemble: ')\n",
    "print(var_column_name_thresholds)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_thresholds)\n",
    "print('Dataframe containing the thresholds: ')\n",
    "df_thresholds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the thresholds for the cold waves, the climatological ensemble and the ground truth for the skill assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the validation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, two different dataframes are created with the threshold for the cold wave \n",
    "# definition. One for regular years and one for leap years. Therefore, the index of the original\n",
    "# dataframe is set to the time and the index of the 29 February is determined. Then, a new \n",
    "# dataframe without the 29 February is created for regular years. The original dataframe is used\n",
    "# for leap years.\n",
    "df_thresholds[time_column_name_thresholds]=pd.to_datetime(df_thresholds[time_column_name_thresholds])\n",
    "df_thresholds = df_thresholds.set_index(time_column_name_thresholds)\n",
    "index_of_february_29 = df_thresholds[((df_thresholds.index.month == 2) & (df_thresholds.index.day == 29))].index\n",
    "df_thresholds_without_29_feb = df_thresholds.drop(index_of_february_29)\n",
    "df_thresholds = df_thresholds.reset_index()\n",
    "df_thresholds_without_29_feb = df_thresholds_without_29_feb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, two different dataframes are created with climatological ensemble. One for \n",
    "# regular years and one for leap years. Therefore, the index of the original dataframe is set \n",
    "# to the time and the index of the 29 February is determined. Then, a new  dataframe without \n",
    "# the 29 February is created for regular years. The original dataframe is used for leap years.\n",
    "df_climatological_ensemble[time_column_name_climatological_ensemble]=pd.to_datetime(df_climatological_ensemble[time_column_name_climatological_ensemble])\n",
    "df_climatological_ensemble = df_climatological_ensemble.set_index(time_column_name_climatological_ensemble)\n",
    "index_of_february_29 = df_climatological_ensemble[((df_climatological_ensemble.index.month == 2) & (df_climatological_ensemble.index.day == 29))].index\n",
    "df_climatological_ensemble_without_29_feb = df_climatological_ensemble.drop(index_of_february_29)\n",
    "df_climatological_ensemble = df_climatological_ensemble.reset_index()\n",
    "df_climatological_ensemble_without_29_feb = df_climatological_ensemble_without_29_feb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the needed thresholds for the respective winter are taken and the respective\n",
    "# winter is extracted from the ground truth and the climatological_ensemble. Then, the cold wave criterion\n",
    "# by Smid et al. (2019) is applied to the climatological_ensemble. In the end, lists\n",
    "# containing the ground truth, the fraction of the climatological ensemble showing a cold \n",
    "# wave and the forecast dates are created.\n",
    "forecast_dates = []\n",
    "\n",
    "list_members_cold_waves_climatological_ensemble = []\n",
    "list_cold_waves_climatological_ensemble = []\n",
    "\n",
    "all_winters_list_cold_waves_ground_truth = []\n",
    "all_winters_list_cold_waves_climatological_ensemble = []\n",
    "\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    if calendar.isleap(start_year_of_winter+1):\n",
    "        threshold_cold_waves = df_thresholds[var_column_name_thresholds]\n",
    "    else:\n",
    "        threshold_cold_waves = df_thresholds_without_29_feb[var_column_name_thresholds]\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "    df_ground_truth_respective_winter = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "    \n",
    "    list_cold_waves_ground_truth = df_ground_truth_respective_winter[var_column_name_ground_truth]\n",
    "    \n",
    "    if calendar.isleap(start_year_of_winter+1):\n",
    "        df_climatological_ensemble_respective_winter = df_climatological_ensemble   \n",
    "    else:\n",
    "        df_climatological_ensemble_respective_winter = df_climatological_ensemble_without_29_feb\n",
    "    \n",
    "    df_climatological_ensemble_time_column = pd.DataFrame()    \n",
    "    df_climatological_ensemble_time_column['time'] = df_climatological_ensemble_respective_winter[time_column_name_climatological_ensemble]\n",
    "       \n",
    "    list_members_cold_waves_climatological_ensemble = []\n",
    "    list_cold_waves_climatological_ensemble = []\n",
    "    \n",
    "    for i in var_column_name_climatological_ensemble:\n",
    "        members_with_cold_waves = apply_cold_wave_definition_smid_et_al_2019(df_climatological_ensemble_time_column, df_climatological_ensemble_respective_winter, i, threshold_cold_waves)          \n",
    "        list_members_cold_waves_climatological_ensemble.append(members_with_cold_waves)\n",
    "        \n",
    "    fraction_of_member_with_cold_waves = np.sum(list_members_cold_waves_climatological_ensemble, axis=0)\n",
    "    list_cold_waves_climatological_ensemble.append(fraction_of_member_with_cold_waves/len(var_column_name_climatological_ensemble))\n",
    "    \n",
    "    all_winters_list_cold_waves_ground_truth.append(list_cold_waves_ground_truth)\n",
    "    all_winters_list_cold_waves_climatological_ensemble.append(np.squeeze(list_cold_waves_climatological_ensemble))\n",
    "    \n",
    "    forecast_dates.append(pd.to_datetime(df_ground_truth_respective_winter[time_column_name_ground_truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the cold wave prediction of the climatological for saving in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the 29th February NaN entry for regular years to its right position (right now, it is\n",
    "# appended at the end of the timeseries, since the timeseries for regular years is one day short,\n",
    "# but this will correspond to 31 December later)\n",
    "cold_waves_with_nan_at_position_of_29_february = []\n",
    "for k in range(len(start_years_of_winter)):\n",
    "    if calendar.isleap(start_years_of_winter[k]+1)==False:\n",
    "        cold_waves_leap_year = list(all_winters_list_cold_waves_climatological_ensemble[k])\n",
    "        cold_waves_leap_year.insert(120, np.nan)\n",
    "        cold_waves_leap_year = cold_waves_leap_year[0:len(cold_waves_leap_year)]\n",
    "        cold_waves_with_nan_at_position_of_29_february.append(cold_waves_leap_year)\n",
    "    else:\n",
    "        cold_waves_with_nan_at_position_of_29_february.append(all_winters_list_cold_waves_climatological_ensemble[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For an easier handling of the data later on, a \"auxiliary date\" is created. This is simply a\n",
    "# timeseries of dates of a leap year winter (here 2003/2004), which is afterwards sorted \n",
    "# chronologically by month (Jan-Dec). The exact year itself does not matter since only the month\n",
    "# and day are relevant for the climatological ensemble and furthermore only these two will be \n",
    "# shown on a plot.\n",
    "auxiliary_time = create_auxiliary_date(config['start_month_winter'], config['start_day_winter'], config['end_month_winter'], config['end_day_winter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list with the predicted cold wave days of the climatological ensemble is converted into a\n",
    "# pandas dataframe and then transposed for a better representation of the data. In a next step,\n",
    "# the time information is added again to the dataframe. Since the climatological_ensemble are the same for\n",
    "# every winter, only 1 column is needed. \n",
    "df_climatological_ensemble_cold_waves = pd.DataFrame(cold_waves_with_nan_at_position_of_29_february)\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.T\n",
    "df_climatological_ensemble_cold_waves['auxiliary_time'] = pd.to_datetime(auxiliary_time)\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves[['auxiliary_time', 0]]\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.rename(columns={0:'Fraction of Ensembles Members \\n Predicting Cold Wave Day'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the climatological ensemble's cold wave days prediction in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the days of the cold wave climatological_ensemble of the climatological ensemble in csv-format.\n",
    "df_climatological_ensemble_cold_waves.to_csv(config['PATH_output_files']+'daily_climatological_ensemble_cold_waves_'+var_column_name_ground_truth+'_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of the BS between the ground truth and the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the daily BS is computed and saved to a list. Furthermore, the forecast time is saved in\n",
    "# continuous form to a list.\n",
    "forecast_time = []\n",
    "bs_daily_one_year = []\n",
    "bs = []\n",
    "bs_winterwise = []\n",
    "\n",
    "for k in range(len(start_years_of_winter)):\n",
    "    forecast_time.extend(forecast_dates[k])\n",
    "    bs_one_year = 0\n",
    "    bs_daily_one_year = []\n",
    "    for l in range(len(all_winters_list_cold_waves_climatological_ensemble[k])):\n",
    "        bs_daily = (all_winters_list_cold_waves_climatological_ensemble[k][l]-all_winters_list_cold_waves_ground_truth[k][l])**2\n",
    "        bs_daily_one_year.append(bs_daily)\n",
    "    bs.extend(np.array(bs_daily_one_year))\n",
    "    bs_winterwise.append(np.array(bs_daily_one_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, a dataframe containing the daily BS values and the corresponding forecasting times is\n",
    "# created. \n",
    "df_skill_measure_bs = pd.DataFrame()\n",
    "df_skill_measure_bs['time'] = forecast_time\n",
    "df_skill_measure_bs['BS'] = np.array(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the BS in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pandas dataframe containing the BS values is saved in csv format. \n",
    "df_skill_measure_bs.to_csv(config['PATH_statistics']+config['model_name']+'_BS_ground_truth_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the predictions of the climatological ensemble together with the ground truth and the BS for a plausibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before plotting, the information about the input data which should be shown in the plot title\n",
    "# is converted to a nice-looking string by creating the line-breaks set in the configuration \n",
    "# file.\n",
    "str_input_info_for_plot_titles = config['input_data_title']\n",
    "str_input_info_for_plot_titles = str_input_info_for_plot_titles.replace('|', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For illustration purposes, the fraction of ensemble members of the climatological ensemble predicting a cold wave\n",
    "# day is plotted with the cold waves in the ground truth. This gives a first impression about\n",
    "# the model's forecast skill.\n",
    "for i in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[i], all_winters_list_cold_waves_ground_truth[i], color='k', linestyle='--', label='Ground Truth')\n",
    "    plt.plot(forecast_dates[i], all_winters_list_cold_waves_climatological_ensemble[i], marker='o', linestyle='', color='r', alpha=0.6, label='climatological_ensemble')    \n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel('Fraction of Ensemble Members \\n Predicting a Cold Wave')\n",
    "    plt.title(config['model_name']+' climatological_ensemble:\\n '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_'+str(start_years_of_winter[i])+'_'+str(start_years_of_winter[i]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BS values for each winter are plotted separately. In combination with the plot above a first plausibility\n",
    "# check is possible. The lower the BS value, the more similar the prediction of the climatological \n",
    "# ensemble and the ground truth have to be.\n",
    "for n in range(len(start_years_of_winter)):\n",
    "    fig = plt.subplots()\n",
    "    plt.plot(forecast_dates[n], bs_winterwise[n], color='r', marker='o', markersize=4, linestyle='--')\n",
    "    plt.axhline(y=np.nanmean(bs_winterwise[n]), color='grey', linestyle='-', label='Wintermean')\n",
    "    plt.legend(bbox_to_anchor=(0, -0.15), loc='upper left')\n",
    "    plt.xlabel(time_column_name_ground_truth)\n",
    "    plt.ylabel('BS')\n",
    "    plt.title('Daily BS of '+config['model_name']+' climatological_ensemble:\\n '+str_input_info_for_plot_titles)\n",
    "    plt.savefig(config['PATH_plots']+config['model_name']+'_BS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_'+str(start_years_of_winter[n])+'_'+str(start_years_of_winter[n]+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the BS for all winters in the evaluation period for a quick overview of the forecasting performance of the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeseries of the daily BS values is plotted for all winters in the evaluation period. \n",
    "plt.plot(forecast_time, bs, marker='s', linestyle='', markersize=2, color='r')\n",
    "plt.xlabel(time_column_name_ground_truth)\n",
    "plt.ylabel('BS')\n",
    "plt.title('Daily BS of '+config['model_name']+' climatological_ensemble: \\n '+str_input_info_for_plot_titles)\n",
    "plt.savefig(config['PATH_plots']+config['model_name']+'_BS_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
