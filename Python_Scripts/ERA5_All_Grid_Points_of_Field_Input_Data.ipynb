{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating \"All grid points of field\" from the Meteorological Predictor Fields as Input for RF-based ML-Models\n",
    "Version 18 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "continuous timeseries of meteorological predictors as 2d-fields in csv-format\n",
    "### Output: csv-file\n",
    "continuous timeseries of all grid points of the meteorological predictors as a long vector per date in csv-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the paths' and files' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed path and file names.\n",
    "PATH_defined_functions = './Defined_Functions/'\n",
    "\n",
    "PATH_input_data = './Data_in_csv_Format/'\n",
    "ifiles_input_data = ['era5_u10_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z100_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z250_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_z500_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_z850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_t850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_H850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_u300_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_msl_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv']\n",
    "\n",
    "PATH_output_file = './Data_in_csv_Format/'\n",
    "file_name_output_file = 'era5_u10_z100_z250_z500_z850_t850_H850_u300_msl_60W_60E_20N_80N_1950_2020_lead_time_14d.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions.\n",
    "import sys\n",
    "sys.path.insert(1,PATH_defined_functions)\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the predictors to be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the desired predictors and set how many of these should be taken from the first \n",
    "# dataframe. From all other dataframes, only 1 predictor is taken (if more are needed, list\n",
    "# these input files multiple times in \"ifiles_input_data\"). It is necessary to take the time as\n",
    "# a predictor since the data will be grouped by date later.\n",
    "desired_predictors = ['time', 'latitude', 'longitude', 'month', 'u10', 'z100', 'z250', 'z500', 'z850', 't850', 'H850', 'u300', 'msl']\n",
    "number_of_predictors_in_first_dataframe = 5\n",
    "time_column_name = 'time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all predictors into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dataframe is created and the desired predictors from the first data file are written\n",
    "# into it.\n",
    "df_combined_input_data = pd.DataFrame()\n",
    "df_input_data = read_in_csv_data(PATH_input_data, ifiles_input_data[0])\n",
    "for i in range(number_of_predictors_in_first_dataframe):\n",
    "    df_combined_input_data[desired_predictors[i]] = df_input_data [desired_predictors[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From all other dataframes, the specified predictor is added to this new dataframe.\n",
    "for k in range(len(ifiles_input_data)-1):\n",
    "    df_input_data = read_in_csv_data(PATH_input_data, ifiles_input_data[k+1])\n",
    "    df_combined_input_data[desired_predictors[i+k+1]] = df_input_data [desired_predictors[i+k+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the time is set as the index and the data is grouped by date.\n",
    "df_combined_input_data[time_column_name] = pd.to_datetime(df_combined_input_data[time_column_name])\n",
    "df_combined_input_data = df_combined_input_data.set_index(time_column_name)\n",
    "ds_input_data_grouped = df_combined_input_data.groupby([df_combined_input_data.index.year, df_combined_input_data.index.month, df_combined_input_data.index.day], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The so grouped data is converted into a pandas dataframe.\n",
    "df_input_data_grouped = pd.DataFrame(ds_input_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is stacked, only the relevant column containing all the predictors is taken.\n",
    "df_input_data_grouped = df_input_data_grouped[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the data so it can be used as input for RF-based ML-models directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step the data is reshaped so that the data can be used directly with the machine \n",
    "# learning model later. Therefore, it needs to have in one dimension the same length as the \n",
    "# ground truth data. Here, this is the time. So for every date, all predictors are put into a \n",
    "# separate row and then appended to a list. The predictors are thereby sorted in the same way\n",
    "# in each row.\n",
    "reshaped_data = []\n",
    "for l in range(len(df_input_data_grouped)):\n",
    "    single_day = np.array(df_input_data_grouped[l])\n",
    "    single_day = single_day.reshape(1,-1)\n",
    "    reshaped_data.append(single_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The so created list containing all the predictors is converted into a pandas dataframe \n",
    "# again.\n",
    "df_reshaped_data = pd.DataFrame(np.squeeze(reshaped_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the time information again to the reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the time got lost by using .groupby(), a separate new dataframe is created containing\n",
    "# only the time. To this dataframe, three new columns are added containing the year, month and \n",
    "# day.\n",
    "df_combined_input_data = df_combined_input_data.reset_index()\n",
    "df_time = pd.DataFrame()\n",
    "df_time[time_column_name] = pd.to_datetime(df_combined_input_data[time_column_name])\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "df_time['year'] = df_time.index.year\n",
    "df_time['month'] = df_time.index.month\n",
    "df_time['day'] = df_time.index.day\n",
    "df_time = df_time.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new dataframe is then grouped by date and 'averaged' resulting in a daily time-\n",
    "# series but separated into year, month and day.\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "ds_time_mean = df_time.groupby([df_time.index.year, df_time.index.month, df_time.index.day], as_index=False).mean().astype(int).astype(str) \n",
    "df_time_mean = pd.DataFrame(ds_time_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The separated timeseries is now combined into a single daily timeseries (nothing needs to be\n",
    "# changed here).str\n",
    "daily_timeseries = (df_time_mean['year'].astype(str)+'-'+df_time_mean['month'].astype(str)+'-'+df_time_mean['day']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next step, the time is added to the dataframe containing the statistics as predictors \n",
    "# (nothing needs to be changed here).\n",
    "df_reshaped_data.insert(0, time_column_name, daily_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublecheck the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is reshaped and sorted correctly.\n",
    "df_reshaped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if everything is sorted, renamed or removed correctly at the end of the\n",
    "# dataframe.\n",
    "df_reshaped_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in csv-format.\n",
    "df_reshaped_data.to_csv(PATH_output_file+file_name_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
