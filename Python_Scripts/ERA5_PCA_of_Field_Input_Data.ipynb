{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating \"Principle Components Analysis (PCA) of field\" from the Meteorological Predictor Fields as Input for RF-based ML-Models\n",
    "Version 18 January 2024, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "continuous timeseries of meteorological predictors as 2d-fields in csv-format\n",
    "### Output: csv-file\n",
    "continuous timeseries of the first 10 principle components of the meteorological predictors per date in csv-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the paths' and files' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the needed path and file names.\n",
    "PATH_defined_functions = './Defined_Functions/'\n",
    "\n",
    "PATH_input_data = './Data_in_csv_Format/'\n",
    "ifiles_input_data = ['era5_u10_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z100_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                     'era5_z250_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_z500_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_z850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_t850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_H850_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_u300_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv',\n",
    "                    'era5_msl_60W_60E_20N_80N_1950_2020_only_Oct_Apr_lead_time_14d.csv']\n",
    "\n",
    "PATH_output_file = './Data_in_csv_Format/'\n",
    "file_name_output_file = 'era5_pca_n10_u10_z100_z250_z500_z850_t850_H850_u300_msl_60W_60E_20N_80N_1950_2020_lead_time_14d.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions.\n",
    "import sys\n",
    "sys.path.insert(1,PATH_defined_functions)\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the predictors to be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the desired predictors. From all dataframes, only 1 predictor is taken (if more are \n",
    "# needed, list these input files multiple times in \"ifiles_input_data\"). The month should not be\n",
    "# included in the predictors list since a PCA over the month is not sensible. Therefore, the \n",
    "# month is added at a later stage to the dataframe.\n",
    "desired_predictors = ['u10', 'z100', 'z250', 'z500', 'z850', 't850', 'H850', 'u300', 'msl']\n",
    "time_column_name = 'time'\n",
    "number_of_latitudes = 40\n",
    "number_of_longitudes = 81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide how many principle components should be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set how many components should be used by the Principal Components Analysis (PCA). \n",
    "number_of_principle_components = 10\n",
    "pca = PCA(n_components=number_of_principle_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the PCA for every predictor field separately and then combine the principle components in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PCA is performed for every day and every predictor field separately. \n",
    "# Therefore, one dataframe is read in and grouped by year, month and days (.groupby()). Then, \n",
    "# one day is selected (.iloc[]) and from the resulting dataframe only the predictor's column is\n",
    "# taken and converted into a numpy array. Then, this column is reshaped into the dimensions of\n",
    "# a field again (.reshape(latitude, longitude)). Then, the PCA is performed (pca.fit_transform).\n",
    "# From the PCA, the singular values (= PCA loadings) are taken and written in to a list. This\n",
    "# list is then appended to list containing all singular values of the predictor field for all\n",
    "# days and from this list, all the singular values are written into a pandas dataframe.\n",
    "field_one_variable_all_days = []\n",
    "df_input_data_pca = pd.DataFrame()\n",
    "\n",
    "for i in range(len(ifiles_input_data)):\n",
    "    df_input_data_one_variable = read_in_csv_data(PATH_input_data, ifiles_input_data[i])\n",
    "    \n",
    "    df_input_data_one_variable[time_column_name] = pd.to_datetime(df_input_data_one_variable[time_column_name])\n",
    "    df_input_data_one_variable = df_input_data_one_variable.set_index(time_column_name)\n",
    "    ds_input_data_one_variable_grouped = df_input_data_one_variable.groupby([df_input_data_one_variable.index.year, df_input_data_one_variable.index.month, df_input_data_one_variable.index.day], as_index=False)\n",
    "    \n",
    "    df_input_data_one_variable_grouped = pd.DataFrame(ds_input_data_one_variable_grouped)\n",
    "\n",
    "    for k in range(len(df_input_data_one_variable_grouped)):\n",
    "        df_input_data_one_variable_one_day = df_input_data_one_variable_grouped.iloc[k]\n",
    "        df_input_data_one_variable_one_day = df_input_data_one_variable_one_day[1]\n",
    "\n",
    "        field_one_variable_one_day = np.array(df_input_data_one_variable_one_day[desired_predictors[i]])\n",
    "        field_one_variable_one_day = field_one_variable_one_day.reshape(number_of_latitudes,number_of_longitudes)\n",
    "        \n",
    "        field_one_variable_all_days.append(field_one_variable_one_day)\n",
    "        \n",
    "    field_one_variable_all_days = np.array(field_one_variable_all_days)\n",
    "    \n",
    "    field_one_variable_all_days = field_one_variable_all_days.reshape(( -1, number_of_latitudes*number_of_longitudes))\n",
    "    \n",
    "    field_one_variable_all_days_fitted = pca.fit_transform(field_one_variable_all_days)\n",
    "              \n",
    "    field_one_variable_all_days_transformed = pca.transform(field_one_variable_all_days)\n",
    "   \n",
    "    field_one_variable_all_days = []\n",
    "            \n",
    "    for l in range(number_of_principle_components):    \n",
    "        df_input_data_pca[desired_predictors[i]+'_n'+str(l+1)] = field_one_variable_all_days_transformed[:,l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the time information again to the reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the time got lost by using .groupby() and is not needed for the PCA, a separate new \n",
    "# dataframe is created containing only the time. To this dataframe, three new columns are added\n",
    "# containing the year, month and day.\n",
    "df_input_data_one_variable = df_input_data_one_variable.reset_index()\n",
    "df_time = pd.DataFrame()\n",
    "df_time[time_column_name] = pd.to_datetime(df_input_data_one_variable[time_column_name])\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "df_time['year'] = df_time.index.year\n",
    "df_time['month'] = df_time.index.month\n",
    "df_time['day'] = df_time.index.day\n",
    "df_time = df_time.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new dataframe is then grouped by date and 'averaged' resulting in a daily time-\n",
    "# series but separated into year, month and day.\n",
    "df_time = df_time.set_index(time_column_name)\n",
    "ds_time_mean = df_time.groupby([df_time.index.year, df_time.index.month, df_time.index.day], as_index=False).mean().astype(int).astype(str) \n",
    "df_time_mean = pd.DataFrame(ds_time_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The separated timeseries is now combined into a single daily timeseries (nothing needs to be\n",
    "# changed here).\n",
    "daily_timeseries = (df_time_mean['year'].astype(str)+'-'+df_time_mean['month'].astype(str)+'-'+df_time_mean['day']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next step, firstly the month is added to the dataframe containing the singular values\n",
    "# of the PCA and then the time.\n",
    "#df_input_data_pca.insert(0, 'month', df_time['month'])\n",
    "df_input_data_pca.insert(0, time_column_name, daily_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublecheck the representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is reshaped and sorted correctly.\n",
    "df_input_data_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check if everything is sorted, renamed or removed correctly at the end of the\n",
    "# dataframe.\n",
    "df_input_data_pca.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in csv-format.\n",
    "df_input_data_pca.to_csv(PATH_output_file+file_name_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
